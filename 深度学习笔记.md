# 1. ä»‹ç»

## 1.1 Anaconda

Anacondaæ˜¯ä¸€ä¸ªåŒ…å«æ•°æ®ç§‘å­¦å¸¸ç”¨åŒ…çš„ Python å‘è¡Œç‰ˆæœ¬ã€‚å®ƒåŸºäº conda â€”â€”ä¸€ä¸ªåŒ…å’Œç¯å¢ƒç®¡ç†å™¨â€”â€”è¡ç”Ÿè€Œæ¥ã€‚ä½ å°†ä½¿ç”¨ conda åˆ›å»ºç¯å¢ƒï¼Œä»¥ä¾¿åˆ†éš”ä½¿ç”¨ä¸åŒ Python ç‰ˆæœ¬å’Œä¸åŒç¨‹åºåŒ…çš„é¡¹ç›®ã€‚ä½ è¿˜å°†ä½¿ç”¨å®ƒåœ¨ç¯å¢ƒä¸­å®‰è£…ã€å¸è½½å’Œæ›´æ–°åŒ…ã€‚

## 1.2 conda

condaæ˜¯ä¸€ä¸ªç¯å¢ƒç®¡ç†å™¨ï¼ŒCondaæ˜¯åœ¨Windowsã€macå’ŒLinuxä¸Šè¿è¡Œçš„å¼€æºè½¯ä»¶åŒ…ç®¡ç†ç³»ç»Ÿå’Œç¯å¢ƒç®¡ç†ç³»ç»Ÿ

Condaå¯ä»¥è½»æ¾åœ°åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šçš„ç¯å¢ƒå’Œç‰ˆæœ¬ä¸­åˆ›å»ºï¼Œä¿å­˜ï¼ŒåŠ è½½å’Œåˆ‡æ¢

ä¾‹å¦‚ï¼šåœ¨æˆ‘ä»¬åšå¤§å‹é¡¹ç›®ä¸­ï¼Œéœ€è¦3.5ç‰ˆæœ¬çš„pythonç¯å¢ƒæ—¶ï¼Œåˆ©ç”¨condaå¯ä»¥é…ç½®éœ€è¦çš„ç¯å¢ƒï¼Œå½“éœ€è¦3.8ç‰ˆæœ¬ç¯å¢ƒæ—¶ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç”¨condaè¿›è¡Œç¯å¢ƒé…ç½®ã€‚æ–¹ä¾¿æˆ‘ä»¬åœ¨ä¹‹åæ›´æ–¹ä¾¿


# 2. ç»ˆç«¯

å¦‚å›¾åœ¨pycharmä¸­çš„Terminalä¹Ÿå¯ä»¥è¿›è¡Œç±»ä¼¼cmdçš„æ“ä½œã€‚

![image-20230512220525451](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230512220525451.png)

## 2.1 conda

æŸ¥çœ‹pythonç‰ˆæœ¬

```
python
python --version
```

æµ‹è¯•condaæ˜¯å¦æ­£å¸¸

```cmd
conda
```

æŸ¥çœ‹condaç‰ˆæœ¬

```
conda -V
conda --version
```

è¿›å…¥baseç¯å¢ƒ

```
activate
```

åˆ›å»ºç¯å¢ƒï¼ˆåˆ›å»º3.8ç‰ˆæœ¬åä¸ºxxxçš„ç¯å¢ƒï¼‰

```
conda create -n xxx python=3.6

egï¼šconda create -n python2 python=python2.7 numpy pandas
#åˆ›å»ºäº†python2ç¯å¢ƒï¼Œpythonç‰ˆæœ¬ä¸º2.7ï¼ŒåŒæ—¶è¿˜å®‰è£…äº†numpy pandasåŒ…
```

 é€‰æ‹©ç¯å¢ƒï¼ˆåä¸ºxxxçš„ç¯å¢ƒï¼‰

```
conda activate xxx
```

é€€å‡ºåˆ°baseç¯å¢ƒ

```
conda deactivate
```

åˆ é™¤æŸä¸ªç¯å¢ƒ

```
conda remove -n env_name --all
conda env remove -n env_name    	#ä¸Šé¢å¤±è´¥æ—¶ç”¨
conda remove package       			#åˆ é™¤å½“å‰ç¯å¢ƒä¸­çš„åŒ…
conda remove -n env_name  package   #åˆ é™¤æŒ‡å®šç¯å¢ƒä¸­çš„åŒ…
```

æŸ¥çœ‹å½“å‰æ‰€æœ‰ç¯å¢ƒ

```
conda  env  list
```

æŸ¥çœ‹å½“å‰ç¯å¢ƒçš„æ‰€æœ‰å®‰è£…åŒ…

```
conda  list  //éœ€è¿›å…¥è¯¥è™šæ‹Ÿç¯å¢ƒ
conda  list  -n  env_name
```

å®‰è£…orå¸è½½åŒ…

```
conda  install  xxx
conda  install  xxx=ç‰ˆæœ¬å·      		  	   # æŒ‡å®šç‰ˆæœ¬å·
conda  install  xxx -i æºåç§°æˆ–é“¾æ¥      		 # æŒ‡å®šä¸‹è½½æºï¼Œç›¸å¯¹ä¸Šé¢2è¡Œæ›´å¿«
conda  install --name env_name package_name  #åœ¨æŒ‡å®šç¯å¢ƒä¸­å®‰è£…åŒ…
conda  uninstall  xxx
```

condaå’Œpipçš„æ•°æ®æº

```
1ã€condaæ•°æ®æºç®¡ç†ï¼š
#æ˜¾ç¤ºç›®å‰condaçš„æ•°æ®æºæœ‰å“ªäº›
conda config --show channels
#æ·»åŠ æ•°æ®æºï¼šä¾‹å¦‚, æ·»åŠ æ¸…åanacondaé•œåƒï¼š
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --set show_channel_urls yes
#åˆ é™¤æ•°æ®æº
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
#æ˜¾ç¤ºç›®å‰pipçš„æ•°æ®æºæœ‰å“ªäº›
pip config list
pip config list --[user|global] # åˆ—å‡ºç”¨æˆ·|å…¨å±€çš„è®¾ç½®
pip config get global.index-url # å¾—åˆ°è¿™keyå¯¹åº”çš„value å¦‚ï¼šhttps://mirrors.aliyun.com/pypi/simple/
#æ·»åŠ æ•°æ®æºï¼šä¾‹å¦‚, æ·»åŠ USTCä¸­ç§‘å¤§çš„æºï¼š
pip config set global.index-url https://mirrors.ustc.edu.cn/pypi/web/simple
#æ·»åŠ å…¨å±€ä½¿ç”¨è¯¥æ•°æ®æº
pip config set global.trusted-host https://mirrors.ustc.edu.cn/pypi/web/simple
# åˆ é™¤
pip config unset key
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
tipsï¼š
#æœ¬äººçš„ ~/.condarc
auto_activate_base: false
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
    show_channel_urls: true
```

## 1.3 cuda







# 3. IDE

## 3.1 pycharm

### 3.1.1 pytharmæ·»åŠ è§£é‡Šå™¨

é€‰æ‹©condaå®‰è£…è·¯å¾„çš„python.exe

![image-20230512222231529](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230512222231529.png)



## 3.2 ç¼–è¾‘å™¨Jupyter





# 4. å¸¸ç”¨åº“(å‡½æ•°)

## 4.1 osåº“

### 4.1.1 os.path

os.path æ¨¡å—æ˜¯ç³»ç»Ÿè·¯å¾„æ“ä½œæ¨¡å—ï¼Œå…¶ä¸­ï¼Œæ–œæ ("/")æ˜¯ linux ç³»ç»Ÿä¸‹çš„è·¯å¾„åˆ†éš”ç¬¦ï¼Œå’Œåæ–œæ ("\")æ˜¯ windows ç³»ç»Ÿä¸‹çš„è·¯å¾„åˆ†éš”ç¬¦ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œåªè¦æä¾›ä¸€ä¸ªåŒ…å«æ–œæ å’Œåæ–œæ çš„å­—ç¬¦ä¸²ï¼Œos.path æ¨¡å—éƒ½èƒ½å¤„ç†ï¼Œå“ªæ€•è¯¥å­—ç¬¦ä¸²ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„çœŸæ­£è·¯å¾„ï¼Œå› ä¸º os.path æ¨¡å—çš„æºç å®ç°å°±æ˜¯æ ¹æ®æ“ä½œç³»ç»Ÿæ¥å¤„ç†æ–œæ å’Œåæ–œæ çš„æ“ä½œçš„ã€‚

#### os.path.join**(path1, path2, ...)**

è·¯å¾„åˆå¹¶å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°ä¼šæŠŠæ‰€æœ‰å‚æ•°åˆå¹¶æˆä¸€ä¸ªè·¯å¾„å­—ç¬¦ä¸²ï¼Œå…¶ä¸­é™¤äº†æœ€åä¸€ä¸ªå‚æ•°ä¹‹å¤–ï¼Œå…¶å®ƒæ‰€æœ‰å‚æ•°éƒ½ä¼šè‡ªåŠ¨åœ¨å­—ç¬¦ä¸²æœ«å°¾æ·»åŠ ç›®å½•åˆ†éš”ç¬¦(æ–œæ æˆ–è€…åæ–œæ )ï¼Œlinuxç³»ç»Ÿä¸‹é»˜è®¤æ·»åŠ æ–œæ ï¼Œwindowsä¸‹é»˜è®¤æ·»åŠ ä¸€ä¸ªåæ–œæ 

### 4.1.2 osæ¨¡å—å¸¸ç”¨å‡½æ•°

#### [os.listdir(path)](https://www.runoob.com/python3/python3-os-listdir.html) 

è¿”å›pathæŒ‡å®šçš„æ–‡ä»¶å¤¹åŒ…å«çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„åå­—çš„listã€‚

```python
import os
path = "dataset\\train\\ants"
img_path_list = os.listdir(path) 
```



## 4.2 [Pillow(PIL)](https://blog.csdn.net/weixin_43790276/article/details/108478270?ydreferer=aHR0cHM6Ly9jbi5iaW5nLmNvbS8%3D)

#### å®‰è£… pip install pillow

```python
#å¯¼åŒ…æ—¶è¦ç”¨PILæ¥å¯¼å…¥ï¼Œè€Œä¸èƒ½ç”¨pillowæˆ–Pillow
import PIL æˆ–
from PIL import Image
```

#### Image.open() ã€Image.show() 

```python
from PIL import Image
 
image = Image.open("yazi.jpg")
image.show()
```



## 4.3 pytorch

*pytorchå¯ä»¥è¯´æ˜¯torchçš„pythonç‰ˆï¼Œå¹¶å¢åŠ äº†å¾ˆå¤šæ–°åŠŸèƒ½*

*å®‰è£…pytorch*ï¼š

è¿›å…¥pytorchå®˜ç½‘é€‰æ‹©å¯¹åº”é…ç½®è¿›è¡Œå®‰è£…

```py
#è¿›å…¥å¯¹åº”è™šæ‹Ÿç¯å¢ƒ
conda activate xxx
#ç‹¬æ˜¾å®‰è£…ï¼š
#è¿™é‡Œè‹¥pythonä¸º3.6ï¼Œå®‰è£…1.8.1
conda install pytorch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1 cudatoolkit=10.2
conda install pytorch torchvision torchaudio pytorch-cuda=11.7

#æ ¸æ˜¾å®‰è£…é€‰cpu=noneé€‰é¡¹

#æ£€æµ‹å®‰è£…æ˜¯å¦æˆåŠŸ
import torch 
print(torch.__version__)    #æ˜¾ç¤ºç‰ˆæœ¬
print("gpu", torch.cuda.is_available())  #gpu TRUE
```



### 4.3.1 [Datasetã€DataLoader](https://blog.csdn.net/weixin_44211968/article/details/123744513?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169405322416800186594999%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169405322416800186594999&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123744513-null-null.142^v93^insert_down28v1&utm_term=torch%20Dataset&spm=1018.2226.3001.4187)

è®­ç»ƒæ¨¡å‹ä¸€èˆ¬éƒ½æ˜¯å…ˆå¤„ç† **æ•°æ®çš„è¾“å…¥é—®é¢˜** å’Œ **é¢„å¤„ç†é—®é¢˜** ã€‚Pytorchæä¾›äº†å‡ ä¸ªæœ‰ç”¨çš„å·¥å…·ï¼štorch.utils.data.Dataset ç±»å’Œ torch.utils.data.DataLoader ç±» ã€‚

æµç¨‹æ˜¯å…ˆæŠŠåŸå§‹æ•°æ®è½¬å˜æˆ torch.utils.data.Dataset ç±»ï¼Œéšåå†æŠŠå¾—åˆ°çš„ torch.utils.data.Dataset ç±»å½“ä½œä¸€ä¸ªå‚æ•°ä¼ é€’ç»™ torch.utils.data.DataLoader ç±»ï¼Œå¾—åˆ°ä¸€ä¸ªæ•°æ®åŠ è½½å™¨ï¼Œè¿™ä¸ªæ•°æ®åŠ è½½å™¨æ¯æ¬¡å¯ä»¥è¿”å›ä¸€ä¸ª Batch çš„æ•°æ®ä¾›æ¨¡å‹è®­ç»ƒä½¿ç”¨ã€‚

åœ¨ pytorch ä¸­ï¼Œæä¾›äº†ä¸€ç§ååˆ†æ–¹ä¾¿çš„æ•°æ®è¯»å–æœºåˆ¶ï¼Œå³ä½¿ç”¨ torch.utils.data.Dataset ä¸ Dataloader ç»„åˆå¾—åˆ°æ•°æ®è¿­ä»£å™¨ã€‚åœ¨æ¯æ¬¡è®­ç»ƒæ—¶ï¼Œåˆ©ç”¨è¿™ä¸ªè¿­ä»£å™¨è¾“å‡ºæ¯ä¸€ä¸ª batch æ•°æ®ï¼Œå¹¶èƒ½åœ¨è¾“å‡ºæ—¶å¯¹æ•°æ®è¿›è¡Œç›¸åº”çš„é¢„å¤„ç†æˆ–æ•°æ®å¢å¹¿æ“ä½œã€‚

#### Dataset

Dataset æ˜¯ä¸€ä¸ª **æ•°æ®é›†** æŠ½è±¡ç±»ï¼Œå®ƒæ˜¯å…¶ä»–æ‰€æœ‰æ•°æ®é›†ç±»çš„çˆ¶ç±»ï¼ˆæ‰€æœ‰å…¶ä»–æ•°æ®é›†ç±»éƒ½åº”è¯¥ç»§æ‰¿å®ƒï¼‰ï¼Œç»§æ‰¿æ—¶éœ€è¦é‡å†™æ–¹æ³• `__len__` å’Œ `__getitem__` ï¼Œ `__len__` æ˜¯æä¾›æ•°æ®é›†å¤§å°çš„æ–¹æ³•ï¼Œ `__getitem__` æ˜¯å¯ä»¥é€šè¿‡ç´¢å¼•å·æ‰¾åˆ°æ•°æ®çš„æ–¹æ³•ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„è‡ªå®šä¹‰æ•°æ®é›†ç±»é‡å†™demo

```py
class MyDataset(Dataset):
    root_dir = ''
    label_dir = ''
    path = ''
    img_path_list = ''
    
    def __init__(self,root_dir,label_dir):
        ...
    
    def __getitem__(self,idx):
        img_name = self.img_path_list[idx]
        img_item_path = os.path.join(...)
    	img = Image.open(img_item_path)
        label = self.label_dir
        return img,label
    
    def __len__(self):
        return len(img_path_list)
```

â€‹			

## 4.4 torch.utils.tenserBoard

### 4.4.1 ä»‹ç»

TensorBoard æ˜¯ä¸€ç»„ç”¨äº[æ•°æ®å¯è§†åŒ–)çš„å·¥å…·ã€‚TensorBoard åŒ…å«åœ¨ TensorFlow åº“ä¸­ï¼Œå¯ä»¥ç›´æ¥ç”¨ï¼Œä½†åœ¨pytorchä¸­ä¸è¡Œï¼Œpytorchè¦å•ç‹¬å®‰è£… TensorBoard å¯ä»¥ä½¿ç”¨**pip install tensorboard**

å®‰è£…

```py
pip install tensorboard
```



### 4.4.2 åŸºæœ¬ä½¿ç”¨

#### 1 æ ‡é‡å±•ç¤ºwriter.add_scalar

```py
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter("logs")
#y=x
for i in range(100):
    writer.add_scalar("y=2x",2i,i)  #å±•ç¤ºy=2xå‡½æ•°å›¾åƒ

writer.close()
```

#### 2 å›¾åƒå±•ç¤ºadd_image

```py
from torch.utils.tensorboard import SummaryWriter            tensorboardå¯è§†åŒ–åº“
import numpy as np								PILç±»å‹ä¸èƒ½ç›´æ¥è¢«writerè¯»å–ï¼Œè½¬æˆnumpy
from PIL import Image							ç”¨äºå¯¼å…¥å›¾ç‰‡

writer = SummaryWriter("logs")

image_path="D:\Pytorch_learn_project\data\\train\\ants_image\\24335309_c5ea483bb8.jpg"   å›¾ç‰‡è·¯å¾„
img_PIL= Image.open(image_path)         æ ¹æ®ä¸Šè¿°è·¯å¾„æ‰“å¼€å›¾ç‰‡
img_array = np.array(img_PIL)			è½¬ä¸ºnumpyç±»å‹ï¼Œæ–¹ä¾¿æŒ‰ç…§numpyç±»å‹ä¿å­˜å›¾ç‰‡çš„æ•°æ®ä¿¡æ¯

#ä½¿ç”¨writer.add_image()å‡½æ•°å±•ç¤ºå›¾ç‰‡ï¼Œæœ€åå…³é—­writer()ï¼Œè¿™é‡Œä¸æ˜¯é»˜è®¤çš„CHWå½¢çŠ¶ï¼Œè¿™é‡Œéœ€è®°å¾—æ ‡æ˜æ•°æ®çš„å½¢çŠ¶
writer.add_image("test1",img_array,2,dataformats='HWC')#2æ˜¯æ­¥é•¿
writer.close()

```

#### 3 ç»ˆç«¯å¯ç”¨tensorboard

```py
#åœ¨ç»ˆç«¯è¾“å…¥å‘½ä»¤å¯ç”¨tensorboardçš„webç«¯
#è®°ä½ä¸€å®šè¦åœ¨å¯¹åº”æ–‡ä»¶çš„ä¸Šçº§ç›®å½•çš„ç»ˆç«¯
tensorboard --logdir=è¦ä¿å­˜çš„ç›®æ ‡ç›®å½• --port=6007
```



## 4.5 torch.tensor

åœ¨[ç¥ç»ç½‘ç»œ](https://so.csdn.net/so/search?q=ç¥ç»ç½‘ç»œ&spm=1001.2101.3001.7020)çš„è®¡ç®—ä¸­ï¼Œæ•°æ®éƒ½æ˜¯ä»¥tensorï¼ˆå¼ é‡ï¼‰çš„å½¢å¼è¿›è¡Œä¼ é€’å’Œè¿ç®—çš„.
tensoræ˜¯å¯¹ä¸€ç±»æ•°å­¦æ¦‚å¿µçš„ä¸€ä¸ªæ¦‚æ‹¬ï¼š

- 0ç»´tensor = æ•°å­— = æ ‡é‡
- 1ç»´tensor = åºåˆ— = å‘é‡
- 2ç»´tensor = 2ç»´åºåˆ— = çŸ©é˜µ
- nç»´tensor = nç»´åºåˆ—

å…¶ä¸­nä¹Ÿä»£è¡¨äº†è®¿é—®tensorä¸­æŸä¸ªå…ƒç´ æ‰€éœ€è¦çš„indexsçš„æ•°é‡ï¼Œä¾‹å¦‚å¯¹äºä¸€ä¸ª2ç»´çš„tensor:

> a = [
> [1, 2],
> [3, 4]
> ]

å½“æˆ‘ä»¬æƒ³è¦è®¿é—®3è¿™ä¸ªå…ƒç´ æ—¶å€™éœ€è¦è¾“å…¥:a[1] [0] å¾—åˆ°3

å¯ä»¥çœ‹åˆ°ï¼Œéœ€è¦2ä¸ªindexs.

Tensorä¸­é™¤äº†æ•°æ®ï¼Œè¿˜åŒ…è£…äº†ç¥ç»ç½‘ç»œä¸­å¦‚æ¢¯åº¦ç­‰çš„ä¸€äº›åŸºæœ¬å±æ€§ï¼Œæ‰€ä»¥è¯´æ•°æ®åœ¨ç¥ç»ç½‘ç»œä¸­ä¸€å®šè¦è½¬æ¢æˆtensorå‹å†è¿›è¡Œè®­ç»ƒ

![image-20230911193346920](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230911193346920.png)

### 4.5.1 tensorä¸Tensorçš„åŒºåˆ«

é¦–å…ˆï¼Œtorch.Tensoræ˜¯ä¸€ä¸ªç±»ï¼Œæ‰€æœ‰çš„tensoréƒ½æ˜¯Tensorçš„ä¸€ä¸ªå®ä¾‹ï¼›è€Œtorch.tensoræ˜¯ä¸€ä¸ªå‡½æ•°ã€‚è¿™ä¹Ÿè¯´æ˜äº†ä¸ºä»€ä¹ˆä½¿ç”¨torch.Tensor()æ²¡æœ‰é—®é¢˜è€Œtorch.tensor()å´æœ‰é—®é¢˜ã€‚
å…¶æ¬¡ï¼Œtorch.tensorä¸»è¦æ˜¯å°†ä¸€ä¸ªdataå°è£…æˆtensorï¼Œå¹¶ä¸”å¯ä»¥æŒ‡å®šrequires_gradã€‚
torch.tensor(data,dtype=None,device=None,requires_grad=False) - > Tensor
æœ€åï¼Œæˆ‘ä»¬æ›´å¤šåœ°ä½¿ç”¨torch.tensorï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨torch.tensor(())æ¥è¾¾åˆ°ä¸torch.Tensor()åŒæ ·çš„æ•ˆæœã€‚

```py
import torch
import numpy as np

a = torch.Tensor([2,3])
print(a.dtype)  # torch.floaat32

b = torch.tensor([2,3])
print(b.dtype)  # torch.int64

c = np.array(2,3)
print(c.dtype) # int64
```

### 4.5.2 tensorçš„ä¸€äº›æ“ä½œ

#### 1 cat()

```py
#å®ç°æ‹¼æ¥
b=torch.randn(3,3)
print(b)
tensor([[-0.0733, -0.4884,  0.9050],
        [-1.2613,  0.8577,  0.2139],
        [ 0.3336, -1.9796, -0.1387]])

e=torch.cat((b,b), dim=0) #dim=0æ˜¯æŒ‰è¡Œæ‹¼æ¥
>>>e
tensor([[-0.0733, -0.4884,  0.9050],
        [-1.2613,  0.8577,  0.2139],
        [ 0.3336, -1.9796, -0.1387],
        [-0.0733, -0.4884,  0.9050],
        [-1.2613,  0.8577,  0.2139],
        [ 0.3336, -1.9796, -0.1387]])


d=torch.cat((b,b),dim=1)  #ç»´åº¦ä¸º1æ˜¯æŒ‰åˆ—æ‹¼æ¥
print(d)
tensor([[-0.0733, -0.4884,  0.9050, -0.0733, -0.4884,  0.9050],
        [-1.2613,  0.8577,  0.2139, -1.2613,  0.8577,  0.2139],
        [ 0.3336, -1.9796, -0.1387,  0.3336, -1.9796, -0.1387]])
```







## 4.6 torchvision/torch

torchvision å·¥å…·åº“æ˜¯ pytorch æ¡†æ¶ä¸‹å¸¸ç”¨çš„å›¾åƒè§†é¢‘å¤„ç†åŒ…ï¼Œå¯ä»¥ç”¨æ¥ç”Ÿæˆå›¾ç‰‡å’Œè§†é¢‘æ•°æ®é›†ï¼ˆtorchvision.datasetsï¼‰ï¼Œåšä¸€äº›å›¾åƒé¢„å¤„ç†(torchvision.transforms)ï¼Œå¯¼å…¥é¢„è®­ç»ƒæ¨¡å‹(torchvision.models)ï¼Œä»¥åŠç”Ÿæˆå’Œä¿å­˜å›¾åƒï¼ˆtorchvision.utilsï¼‰ã€‚

### 4.6.1 transforms

transformså‡½æ•°å¯¹å›¾åƒåšé¢„å¤„ç†å¯ä»¥æ˜¯ï¼šå½’ä¸€åŒ–(normalize)ï¼Œå°ºå¯¸å‰ªè£(resize)ï¼Œç¿»è½¬(flip) ç­‰ã€‚

ä¸Šé¢çš„è¿™äº›æ­¥éª¤å®é™…æ“ä½œèµ·æ¥å¾€å¾€æ˜¯ä¸€ç³»åˆ—çš„ï¼Œæ­¤æ—¶å¯ä»¥ç”¨composeå°†è¿™äº›å›¾åƒé¢„å¤„ç†æ“ä½œè¿èµ·æ¥ã€‚

#### 1 transforms.ToTensor

````py
- å¯ä»¥å°†PILå’Œnumpy.ndarryæ ¼å¼çš„æ•°æ®ä»[0,255]èŒƒå›´è½¬æ¢åˆ°[0,1] ï¼Œå…¶å®å†…éƒ¨å°±æ˜¯å°†åŸå§‹æ•°æ®ç›´æ¥é™¤ä»¥255ã€‚
- å¦å¤–åŸå§‹æ•°æ®çš„shapeæ˜¯ï¼ˆH x W x Cï¼‰ï¼Œé€šè¿‡`transforms.ToTensor()`åshapeä¼šå˜ä¸ºï¼ˆC x H x Wï¼‰ã€‚

```py
import cv2
import numpy as np
import torch
from torchvision import transforms

#åŸå§‹æ•°æ®æ¨¡å‹
data = np.array([
                [[1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1]],
                [[2,2,2],[2,2,2],[2,2,2],[2,2,2],[2,2,2]],
                [[3,3,3],[3,3,3],[3,3,3],[3,3,3],[3,3,3]],
                [[4,4,4],[4,4,4],[4,4,4],[4,4,4],[4,4,4]],
                [[5,5,5],[5,5,5],[5,5,5],[5,5,5],[5,5,5]]
        ],dtype='uint8')

#toTensorè½¬æ¢
data = transforms.ToTensor()(data)

#è¾“å‡º
print(data)
print(data.shape) #torch.Size([3, 5, 5])CHW
--------------------------------------------------------
#1/255=0.0039
tensor([[[0.0039, 0.0039, 0.0039, 0.0039, 0.0039],
         [0.0078, 0.0078, 0.0078, 0.0078, 0.0078],
         [0.0118, 0.0118, 0.0118, 0.0118, 0.0118],
         [0.0157, 0.0157, 0.0157, 0.0157, 0.0157],
         [0.0196, 0.0196, 0.0196, 0.0196, 0.0196]],
        .......
         [[0.0039, 0.0039, 0.0039, 0.0039, 0.0039],
         [0.0078, 0.0078, 0.0078, 0.0078, 0.0078],
         [0.0118, 0.0118, 0.0118, 0.0118, 0.0118],
         [0.0157, 0.0157, 0.0157, 0.0157, 0.0157],
         [0.0196, 0.0196, 0.0196, 0.0196, 0.0196]]])
```

#ToTensoråŠŸèƒ½æ˜¯å°† PIL Image ç±»å‹ æˆ–è€…numpy.ndarrayç±»å‹çš„å›¾ç‰‡å¯¹è±¡è½¬æ¢ä¸º tensorç±»å‹ã€‚from torchvision import transforms

#è¿™æ˜¯å°†PILimageç±»å‹è½¬æ¢æˆtensorç±»å‹ï¼Œç›´æ¥ç”¨transformsçš„è½¬æ¢å·¥å…·
from PIL import Image
from torchvision import transforms

img_path = "testdata/train/ants_image/6743948_2b8c096dda.jpg"
img = Image.open(img_path)
tensor_tool = transforms.ToTensor()
tensor_img = tensor_tool(img)
print(tensor_img)

#è¿™å…ˆå¾—åˆ°numpy.ndarryç±»å‹å†è½¬æ¢æˆtensorç±»å‹ï¼Œå¾—åˆ°ndarryç±»å‹éœ€è¦ä½¿ç”¨opencvï¼ˆcv2ï¼‰
````

#### 2 [transforms.Normalize](https://blog.csdn.net/qq_40507857/article/details/116600119?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169448288016800227484660%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169448288016800227484660&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-116600119-null-null.142^v93^insert_down28v1&utm_term=transforms.normalize&spm=1018.2226.3001.4187&ydreferer=aHR0cHM6Ly9zby5jc2RuLm5ldC9zby9zZWFyY2g%2Fc3BtPTEwMDEuMjEwMS4zMDAxLjQ0OTgmcT10cmFuc2Zvcm1zLm5vcm1hbGl6ZSZ0PSZ1PQ%3D%3D)

![image-20220416200305159](https://img-blog.csdnimg.cn/img_convert/c9ac9390e825a69f6af3763baac8852e.png#pic_center)

å¯ä»¥çœ‹åˆ°è¿™ä¸ªå‡½æ•°çš„è¾“å‡º`output[channel] = (input[channel] - mean[channel]) / std[channel]`ã€‚è¿™é‡Œ[channel]çš„æ„æ€æ˜¯æŒ‡å¯¹ç‰¹å¾å›¾çš„æ¯ä¸ªé€šé“éƒ½è¿›è¡Œè¿™æ ·çš„æ“ä½œã€‚ã€meanä¸ºå‡å€¼ï¼Œstdä¸ºæ ‡å‡†å·®ã€‘

è¿™é‡Œçš„ç¬¬ä¸€ä¸ªå‚æ•°ï¼ˆ0.5ï¼Œ0.5ï¼Œ0.5ï¼‰è¡¨ç¤ºæ¯ä¸ªé€šé“çš„å‡å€¼éƒ½æ˜¯0.5ï¼Œç¬¬äºŒä¸ªå‚æ•°ï¼ˆ0.5ï¼Œ0.5ï¼Œ0.5ï¼‰è¡¨ç¤ºæ¯ä¸ªé€šé“çš„æ–¹å·®éƒ½ä¸º0.5ã€‚ã€å› ä¸ºå›¾åƒä¸€èˆ¬æ˜¯ä¸‰ä¸ªé€šé“ï¼Œæ‰€ä»¥è¿™é‡Œçš„å‘é‡éƒ½æ˜¯1x3çš„ğŸµğŸµğŸµã€‘æœ‰äº†è¿™ä¸¤ä¸ªå‚æ•°åï¼Œå½“æˆ‘ä»¬ä¼ å…¥ä¸€ä¸ªå›¾åƒæ—¶ï¼Œå°±ä¼šæŒ‰ç…§ä¸Šé¢çš„å…¬å¼å¯¹å›¾åƒè¿›è¡Œå˜æ¢ã€‚ã€**æ³¨æ„ï¼šè¿™é‡Œè¯´å›¾åƒå…¶å®ä¹Ÿä¸å¤Ÿå‡†ç¡®ï¼Œå› ä¸ºè¿™ä¸ªå‡½æ•°ä¼ å…¥çš„æ ¼å¼ä¸èƒ½ä¸ºPIL Imageï¼Œæˆ‘ä»¬åº”è¯¥å…ˆå°†å…¶è½¬æ¢ä¸ºTensoræ ¼å¼**ã€‘è¯´äº†è¿™ä¹ˆå¤šï¼Œé‚£ä¹ˆè¿™ä¸ªå‡½æ•°åˆ°åº•æœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿæˆ‘ä»¬é€šè¿‡å‰é¢çš„ToTensorå·²ç»å°†æ•°æ®å½’ä¸€åŒ–åˆ°äº†0-1ä¹‹é—´ï¼Œç°åœ¨åˆæ¥ä¸Šäº†ä¸€ä¸ªNormalizeå‡½æ•°æœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿå…¶å®Normalizeå‡½æ•°åšçš„æ˜¯å°†æ•°æ®å˜æ¢åˆ°äº†[-1,1]ä¹‹é—´ã€‚ä¹‹å‰çš„æ•°æ®ä¸º0-1ï¼Œå½“å–0æ—¶ï¼Œoutput =ï¼ˆ0 - 0.5ï¼‰/ 0.5 = -1ï¼›å½“å–1æ—¶ï¼Œoutput =ï¼ˆ1 - 0.5ï¼‰/ 0.5 = 1ã€‚è¿™æ ·å°±æŠŠæ•°æ®ç»Ÿä¸€åˆ°äº†[-1ï¼Œ1]ä¹‹é—´äº†ğŸŒ±ğŸŒ±ğŸŒ±é‚£ä¹ˆé—®é¢˜åˆæ¥äº†ï¼Œæ•°æ®ç»Ÿä¸€åˆ°[-1ï¼Œ1]æœ‰ä»€ä¹ˆå¥½å¤„å‘¢ï¼Ÿæ•°æ®å¦‚æœåˆ†å¸ƒåœ¨(0,1)ä¹‹é—´ï¼Œå¯èƒ½å®é™…çš„biasï¼Œå°±æ˜¯ç¥ç»ç½‘ç»œçš„è¾“å…¥bä¼šæ¯”è¾ƒå¤§ï¼Œè€Œæ¨¡å‹åˆå§‹åŒ–æ—¶b=0çš„ï¼Œè¿™æ ·ä¼šå¯¼è‡´ç¥ç»ç½‘ç»œæ”¶æ•›æ¯”è¾ƒæ…¢ï¼Œç»è¿‡Normalizeåï¼Œå¯ä»¥åŠ å¿«æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦ã€‚ã€è¿™å¥è¯æ˜¯å†ç½‘ç»œä¸Šæ‰¾åˆ°æœ€å¤šçš„è§£é‡Šï¼Œè‡ªå·±ä¹Ÿä¸ç¡®å®šå…¶æ­£ç¡®æ€§ã€‘

â€ƒâ€ƒè¯»åˆ°è¿™é‡Œå¤§å®¶æ˜¯ä¸æ˜¯ä»¥ä¸ºå°±å®Œäº†å‘¢ï¼Ÿè¿™é‡Œè¿˜æƒ³å’Œå¤§å®¶å” ä¸Šä¸€å” ğŸ“ğŸ“ğŸ“ä¸Šé¢çš„ä¸¤ä¸ªå‚æ•°ï¼ˆ0.5ï¼Œ0.5ï¼Œ0.5ï¼‰æ˜¯æ€ä¹ˆå¾—æ¥çš„å‘¢ï¼Ÿè¿™æ˜¯æ ¹æ®æ•°æ®é›†ä¸­çš„æ•°æ®è®¡ç®—å‡ºçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œæ‰€ä»¥å¾€å¾€ä¸åŒçš„æ•°æ®é›†è¿™ä¸¤ä¸ªå€¼æ˜¯ä¸åŒçš„
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

ç»è¿‡ä¸Šé¢normalize()çš„å˜æ¢åå˜æˆäº†å‡å€¼ä¸º0 æ–¹å·®ä¸º1ï¼ˆå…¶å®å°±æ˜¯æœ€å¤§æœ€å°å€¼ä¸º1å’Œ-1ï¼‰

æ¯ä¸ªæ ·æœ¬å›¾åƒå˜æˆäº†å‡å€¼ä¸º0 æ–¹å·®ä¸º1 çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œè¿™å°±æ˜¯æœ€æ™®é€šï¼ˆç§‘å­¦ç ”ç©¶ä»·å€¼æœ€å¤§çš„ï¼‰çš„æ ·æœ¬æ•°æ®äº†



#### 3 [transforms.Resize()](https://blog.csdn.net/qq_35008185/article/details/118224044?ops_request_misc=&request_id=&biz_id=102&utm_term=transforms.resize&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-118224044.nonecase&spm=1018.2226.3001.4187)

è°ƒæ•´**PILImageå¯¹è±¡**çš„å°ºå¯¸ï¼Œæˆ–ç»“åˆCompose([...])ä½¿ç”¨

> æç¤ºï¼šä¸èƒ½æ˜¯ç”¨**io.imreadæˆ–è€…cv2.imread**è¯»å–çš„å›¾ç‰‡ï¼Œè¿™ä¸¤ç§æ–¹æ³•å¾—åˆ°çš„æ˜¯**ndarray**ã€‚

```py
#åŒæ—¶æŒ‡å®šé•¿å®½
transforms.Resize([h, w])
#å°†å›¾ç‰‡ç¼©æ”¾è‡³xï¼Œé•¿å®½æ¯”ä¿æŒä¸å˜
transforms.Resize(x)
```



#### 4 [transforms.RandomCrop()](https://blog.csdn.net/u011995719/article/details/85107009?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169460376016800197090384%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169460376016800197090384&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-85107009-null-null.142^v93^insert_down28v1&utm_term=transforms.randomcrop%28%29&spm=1018.2226.3001.4187)

```py
class torchvision.transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode=â€˜constantâ€™)
'''
åŠŸèƒ½ï¼šä¾æ®ç»™å®šçš„sizeéšæœºè£å‰ª
å‚æ•°ï¼š
size- (sequence or int)ï¼Œè‹¥ä¸ºsequence,åˆ™ä¸º(h,w)ï¼Œè‹¥ä¸ºintï¼Œåˆ™(size,size)

padding-(sequence or int, optional)ï¼Œæ­¤å‚æ•°æ˜¯è®¾ç½®å¡«å……å¤šå°‘ä¸ªpixelã€‚
å½“ä¸ºintæ—¶ï¼Œå›¾åƒä¸Šä¸‹å·¦å³å‡å¡«å……intä¸ªï¼Œä¾‹å¦‚padding=4ï¼Œåˆ™ä¸Šä¸‹å·¦å³å‡å¡«å……4ä¸ªpixelï¼Œè‹¥ä¸º3232ï¼Œåˆ™ä¼šå˜æˆ4040ã€‚
å½“ä¸ºsequenceæ—¶ï¼Œè‹¥æœ‰2ä¸ªæ•°ï¼Œåˆ™ç¬¬ä¸€ä¸ªæ•°è¡¨ç¤ºå·¦å³æ‰©å……å¤šå°‘ï¼Œç¬¬äºŒä¸ªæ•°è¡¨ç¤ºä¸Šä¸‹çš„ã€‚å½“æœ‰4ä¸ªæ•°æ—¶ï¼Œåˆ™ä¸ºå·¦ï¼Œä¸Šï¼Œå³ï¼Œä¸‹ã€‚

fill- (int or tuple) å¡«å……çš„å€¼æ˜¯ä»€ä¹ˆï¼ˆä»…å½“å¡«å……æ¨¡å¼ä¸ºconstantæ—¶æœ‰ç”¨ï¼‰ã€‚intæ—¶ï¼Œå„é€šé“å‡å¡«å……è¯¥å€¼ï¼Œå½“é•¿åº¦ä¸º3çš„tupleæ—¶ï¼Œè¡¨ç¤ºRGBé€šé“éœ€è¦å¡«å……çš„å€¼ã€‚

padding_mode- å¡«å……æ¨¡å¼ï¼Œè¿™é‡Œæä¾›äº†4ç§å¡«å……æ¨¡å¼ï¼Œ1.constantï¼Œå¸¸é‡ã€‚2.edge æŒ‰ç…§å›¾ç‰‡è¾¹ç¼˜çš„åƒç´ å€¼æ¥å¡«å……ã€‚				  3.reflectï¼Œæš‚ä¸äº†è§£ã€‚ 4. symmetricï¼Œæš‚ä¸äº†è§£ã€‚
'''
```

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

#### 5 transforms.Compose()

ä¸€èˆ¬ç”¨Compose**æŠŠå¤šä¸ªæ­¥éª¤æ•´åˆåˆ°ä¸€èµ·**ï¼š

```py
transforms.Compose([
 
    transforms.CenterCrop(10),
    transforms.ToTensor(),
 
])

#ä¹Ÿå¯ä»¥æå‰å®šä¹‰å†ç›´æ¥æ”¾è¿›å»
trans_toTensor = transforms.ToTensor()
trans_crop = transforms.CenterCrop(10)
transforms.Compose([trans_crop, trans_toTensor])
```





### 4.6.2 torchvision.datasets

#### COCOï¼šç›®æ ‡æ£€æµ‹ï¼Œè¯­ä¹‰åˆ†å‰²

#### MNISTï¼šæ‰‹å†™æ–‡å­—

#### CIFARï¼šç‰©ä½“è¯†åˆ«

```py
CIFAR10çš„10ä¸ªclassesï¼šairplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck
```

```py
torchvision.datasets.CIFAR10(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)
root:ç›®å½•
transformï¼šæ˜¯å¦éœ€è¦transformså¤„ç†å›¾ç‰‡
downloadè‹¥ä¸ºtrueï¼Œåˆ™ä¼šä»ç½‘ä¸Šè‡ªåŠ¨ä¸‹è½½æ•°æ®é›†ï¼Œå¦åˆ™è¦è‡ªå·±ä¸‹è½½ï¼Œä¸€èˆ¬è®¾ç½®ä¸ºtrue
```

```py
import torchvision
from torch.utils.tensorboard import SummaryWriter

dataset_transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])

#datasetsè‹¥å‘ç°æ•°æ®é›†å·²ç»ä¸‹è½½å¹¶æ ¡éªŒé€šè¿‡ï¼Œåˆ™ä¸ä¼šé‡æ–°ä¸‹è½½
train_set = torchvision.datasets.CIFAR10(root="./dataset", train=True, transform=dataset_transform, download=True)
test_set = torchvision.datasets.CIFAR10(root="./dataset", train=False, transform=dataset_transform, download=True)


print(test_set[0])#(<PIL.Image.Image image mode=RGB size=32x32 at 0x2176E5FD0C8>, 3)

print(test_set.classes) #airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck

img, target = test_set[0]
print(img)#<PIL.Image.Image image mode=RGB size=32x32 at 0x2541358AA88>
print(target)#3
print(test_set.classes[target])#cat

#ç”»å›¾
writer = SummaryWriter('summary_event')
for i in range(10):
    set_img, target = test_set[i]
    writer.add_image('cifar10', set_img, i)
```



### 4.6.3 torch.nn

#### nn.Module

æä¾›äº†ä¸€äº›æ¯”è¾ƒå¸¸è§çš„ç¥ç»ç½‘ç»œï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒçš„

è‡ªå®šä¹‰ç¥ç»ç½‘ç»œï¼Œç»§æ‰¿nn.Moduleæ—¶ï¼Œéœ€è¦é‡å†™initå’Œforwardå‡½æ•°

***è‡ªå®šä¹‰ä¸€ä¸ªç±»ï¼Œç»§æ‰¿è‡ªModuleç±»ï¼Œå¹¶ä¸”ä¸€å®šè¦å®ç°ä¸¤ä¸ªåŸºæœ¬çš„å‡½æ•°ï¼Œç¬¬ä¸€æ˜¯æ„é€ å‡½æ•°initï¼Œç¬¬äºŒä¸ªæ˜¯å±‚çš„é€»è¾‘è¿ç®—å‡½æ•°ï¼Œå³æ‰€è°“çš„å‰å‘è®¡ç®—å‡½æ•°forwardå‡½æ•°ã€‚***

```py
#è‡ªå®šä¹‰ä¸€ä¸ªç±»ï¼Œç»§æ‰¿è‡ªModuleç±»ï¼Œå¹¶ä¸”ä¸€å®šè¦å®ç°ä¸¤ä¸ªåŸºæœ¬çš„å‡½æ•°ï¼Œç¬¬ä¸€æ˜¯æ„é€ å‡½æ•°__init__ï¼Œç¬¬äºŒä¸ªæ˜¯å±‚çš„é€»è¾‘è¿ç®—å‡½æ•°ï¼Œå³æ‰€è°“çš„å‰å‘è®¡ç®—å‡½æ•°forwardå‡½æ•°ã€‚
import torch
from torch import nn

class Tudui(nn.Module):
    def __init__(self):
        super().__init__()
    
    def forward(self, input):
        out = inout + 1
        return output
```



#### nn.functional.conv2d

```py
#è¾“å…¥å‚æ•°ï¼Œä¸»è¦è¿˜æ˜¯inputï¼Œ kernel, stride
def conv2d(input: Tensor, weight: Tensor, bias: Optional[Tensor]=None, 
           stride: Union[_int, _size]=1, padding: Union[_int, _size]=0, 
           dilation: Union[_int, _size]=1, groups: _int=1) -> Tensor: ...ï¼Œ
```

```py
import torch

input = torch.tensor([
    [1, 2, 0, 3, 1],
    [0, 1, 2, 3, 1],
    [1, 2, 1, 0, 0],
    [5, 2, 3, 1, 1],
    [2, 1, 0, 1, 1]
])

kernel = torch.tensor([
    [1, 2, 1],
    [0, 1, 0],
    [2, 1, 0]
])

input = torch.reshape(input, (1, 1, 5, 5))
kernel = torch.reshape(kernel, (1, 1, 3, 3))

torch.nn.functional.conv2d(input, kernel, stride=1)
```

![image-20230914202328633](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230914202328633.png)





#### [nn.Conv2d](https://blog.csdn.net/qq_34243930/article/details/107231539?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169474775616800211533990%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169474775616800211533990&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-107231539-null-null.142^v94^insert_down28v1&utm_term=nn.CONV2d&spm=1018.2226.3001.4187&ydreferer=aHR0cHM6Ly9zby5jc2RuLm5ldC9zby9zZWFyY2g%2Fc3BtPTEwMDEuMjEwMS4zMDAxLjQ0OTgmcT1ubi5DT05WMmQmdD0mdT0%3D)

```py
#å‚æ•°è¯¦è§£
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
```

outputçš„H,Wè®¡ç®—å…¬å¼

![image-20230915111908894](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230915111908894.png)

```py
import torchvision
from torch import nn
from torch.nn import Conv2d
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("dataset", train=False,
                                       transform=torchvision.transforms.ToTensor(), download=True)

dataloader = DataLoader(dataset, batch_size=64)

print(dataset.__len__()) #10000

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui,self).__init__()
        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)

    #åœ¨å‰å‘ä¼ æ’­forwardå‡½æ•°é‡Œé¢å®ç°å‰å‘è¿ç®—ã€‚
    def forward(self, x):
        x = self.conv1(x)
        return x

tudui = Tudui()

for data in dataloader:
    imgs, targets = data
    output = tudui(imgs)
    print(imgs.shape) #torch.Size([64, 3, 32, 32])
    print(output.shape) #torch.Size([64, 6, 30, 30])--->è¿™é‡Œè¾“å‡ºé€šé“å˜æˆäº†6ï¼Œæ ¹æ®ä¸Šå›¾å…¬å¼ï¼Œtensorå°ºå¯¸ä¹Ÿè¢«å‹ç¼©
    
    #è‹¥è¦è¿›è¡Œtensorboardï¼Œåˆ™éœ€è¿›è¡Œreshapeï¼Œå› ä¸ºå›¾ç‰‡çš„æ˜¾ç¤ºæ˜¯3é€šé“
    torch.reshape(output, (-1,3,30,30))
```



#### nn.MaxPool2d

ä½œç”¨:
*å¯¹é‚»åŸŸå†…ç‰¹å¾ç‚¹å–æœ€å¤§*
å‡å°**å·ç§¯å±‚å‚æ•°è¯¯å·®**é€ æˆä¼°è®¡**å‡å€¼çš„åç§»**çš„è¯¯å·®ï¼Œæ›´å¤šçš„ä¿ç•™çº¹ç†ä¿¡æ¯ã€‚

```py
#å‚æ•° ä¸€èˆ¬åªå¡«size
MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)

#stride é»˜è®¤å€¼æ˜¯ kernel_size
#dilation (int or tuple, optional)ã€å¯é€‰ã€‘ï¼šä¸€ä¸ªæ§åˆ¶çª—å£ä¸­å…ƒç´ æ­¥å¹…çš„å‚æ•°
#ceil_mode (bool)ã€å¯é€‰ã€‘ï¼šå¦‚æœç­‰äºTrueï¼Œè®¡ç®—è¾“å‡ºä¿¡å·å¤§å°çš„æ—¶å€™ï¼Œå¦‚æœè¶…å‡ºèŒƒå›´ä¹Ÿä¼šè®¡ç®—ï¼Œä¼šä½¿ç”¨å‘ä¸Šå–æ•´ï¼Œä»£æ›¿é»˜è®¤çš„å‘ä¸‹å–æ•´çš„æ“ä½œ
```



#### nn.ReLU/nn.Sigmoid

```py
torch.nn.ReLU(inplace=False)
```



#### [nn.Linear](https://blog.csdn.net/sazass/article/details/123568203?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169508710916800185813549%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169508710916800185813549&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-123568203-null-null.142^v94^insert_down28v1&utm_term=torch%20linear&spm=1018.2226.3001.4187)

Linearè¿ç®—çš„æœ¬è´¨å°±æ˜¯å¤šç»´ï¼ˆçŸ©é˜µï¼‰çš„ä¹˜æ³•åŠ åç½®

```py
torch.nn.Linear(in_features, # è¾“å…¥çš„ç¥ç»å…ƒä¸ªæ•°
           out_features, # è¾“å‡ºç¥ç»å…ƒä¸ªæ•°
           bias=True # æ˜¯å¦åŒ…å«åç½®
           )
'''
in_featureï¼š intå‹, åœ¨forwardä¸­è¾“å…¥Tensoræœ€åä¸€ç»´(ç¬¬ä¸‰ä½)çš„é€šé“æ•°

out_featureï¼š intå‹, åœ¨forwardä¸­è¾“å‡ºTensoræœ€åä¸€ç»´çš„é€šé“æ•°

bias: boolå‹ï¼Œ Linearçº¿æ€§å˜æ¢ä¸­æ˜¯å¦æ·»åŠ biasåç½®
'''
```

```py
#ç¤ºä¾‹
X = torch.Tensor([
    [0.1,0.2,0.3,0.3,0.3],
    [0.4,0.5,0.6,0.6,0.6],
    [0.7,0.8,0.9,0.9,0.9],
])
>>>X
tensor([[0.1000, 0.2000, 0.3000, 0.3000, 0.3000],
        [0.4000, 0.5000, 0.6000, 0.6000, 0.6000],
        [0.7000, 0.8000, 0.9000, 0.9000, 0.9000]])
#å®šä¹‰æ¨¡å‹-------------------------------------------
model = nn.Linear(in_features=5, out_features=10, bias=True)

model(X).size()#torch.Size([3, 10])
```



#### nn.Sequential

ä¸€ä¸ªåºåˆ—å®¹å™¨ï¼Œç”¨äºæ­å»ºç¥ç»ç½‘ç»œçš„æ¨¡å—è¢«æŒ‰ç…§è¢«ä¼ å…¥æ„é€ å™¨çš„é¡ºåºæ·»åŠ åˆ°nn.Sequential()å®¹å™¨ä¸­ã€‚

åˆ©ç”¨nn.Sequential()æ­å»ºå¥½æ¨¡å‹æ¶æ„ï¼Œæ¨¡å‹å‰å‘ä¼ æ’­æ—¶è°ƒç”¨forward()æ–¹æ³•ï¼Œæ¨¡å‹æ¥æ”¶çš„è¾“å…¥é¦–å…ˆè¢«ä¼ å…¥nn.Sequential()åŒ…å«çš„ç¬¬ä¸€ä¸ªç½‘ç»œæ¨¡å—ä¸­ã€‚ç„¶åï¼Œç¬¬ä¸€ä¸ªç½‘ç»œæ¨¡å—çš„è¾“å‡ºä¼ å…¥ç¬¬äºŒä¸ªç½‘ç»œæ¨¡å—ä½œä¸ºè¾“å…¥ï¼ŒæŒ‰ç…§é¡ºåºä¾æ¬¡è®¡ç®—å¹¶ä¼ æ’­ï¼Œç›´åˆ°nn.Sequential()é‡Œçš„æœ€åä¸€ä¸ªæ¨¡å—è¾“å‡ºç»“æœã€‚

***è¿™é‡Œä»¥å¦‚ä¸‹CIFAR10çš„ä¸€ä¸ªåˆ†ç±»æ¨¡å‹ä¸ºä¾‹ï¼Œå°†æ¨¡å‹è¿›è¡Œæ­å»ºï¼š***

***å¯ä»¥çœ‹å‡ºæœ€åç”Ÿæˆäº†ä¸€ä¸ªé•¿åº¦ä¸º10çš„tensorï¼Œæ­£å¥½å¯¹åº”è¯¥æ•°æ®é›†çš„10ä¸ªclasses***

![image-20230918111430252](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230918111430252.png)

```py
from torch import nn
from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear


class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        )

    def forward(self, x):
        s = self.model(x)
        return x
    
tudui = Tudui()
input = torch.ones(64, 3, 32, 32)
output = tudui(input)
print(output.shape)

#å¯ä»¥é€šè¿‡tensorboardè¿›è¡Œç½‘ç»œæ¨¡å‹å¯è§†åŒ–
writer = SummaryWriter('./logs_model')
writer.add_graph(tudui, input)
writer.close()
```



#### nn.L1Loss()

L1Loss è®¡ç®—æ–¹æ³•æ¯”è¾ƒç®€å•ï¼ŒåŸç†å°±æ˜¯å–é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„ç»å¯¹è¯¯å·®çš„å¹³å‡æ•°ã€‚è®¡ç®—å…¬å¼å¦‚ä¸‹

![img](https://img-blog.csdnimg.cn/20191202215436113.png)

```py
#æŸå¤±å‡½æ•°nn.L1Loss()   ä½œç”¨å…¶å®å°±æ˜¯è®¡ç®—ç½‘ç»œè¾“å‡ºä¸æ ‡ç­¾ä¹‹å·®çš„ç»å¯¹å€¼ï¼Œè¿”å›çš„æ•°æ®ç±»å‹å¯ä»¥æ˜¯å¼ é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯æ ‡é‡ã€‚
#å‚æ•°å¯ä»¥è®¾ç½®å–ä¸å–å¹³å‡å€¼
nn.L1Loss(size_average=True, reduce=False,reduction='mean')
```

```py
# output ä¸ºç½‘ç»œçš„è¾“å‡º
# target ä¸ºç›®æ ‡è¾“å‡ºå³å¯¹åº”è¾“å…¥çœŸå®çš„æ ‡ç­¾
output = torch.ones(2, 3, requires_grad=True)*2.5
target = torch.ones(1, 3)

LOSSresult = nn.L1Loss()
result = LOSSresult(output, target)
 
print('æ±‚å¹³å‡:{}'.format(result))
```



#### **nn.MSELoss**

nn.MSELossï¼šè®¡ç®—å…¬å¼æ˜¯é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å¹³æ–¹å’Œçš„å¹³å‡æ•°ã€‚

![img](https://img-blog.csdnimg.cn/20191202215934649.png)

```py
torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')
```

```py

outputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

outputs = torch.reshape(outputs, (1,1,1,3))
targets = torch.reshape(targets, (1,1,1,3))

loss_mse = MSELoss()
result_mse = loss_mse(inputs, targets)

print(result_mse) #Tensor(1.333)  --->  (0+0+(3-5)^2)/3=4/3=1.333
```



#### nn.CrossEntropyLoss

nn.CrossEntropyLossæ˜¯[pytorch](https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020)ä¸‹çš„**äº¤å‰ç†µæŸå¤±å‡½æ•°**ï¼Œç”¨äºåˆ†ç±»ä»»åŠ¡ä½¿ç”¨

> æŸå¤±å‡½æ•°çš„ä¸¤å¤§ä½œç”¨ï¼š
>
> 1. è®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·
> 2. ä¸ºæˆ‘ä»¬æ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ®ï¼ˆé€šè¿‡åå‘ä¼ æ’­ï¼‰

è®¡ç®—å…¬å¼ï¼šxå°±æ˜¯ç½‘ç»œçš„outputsï¼Œå¯ä»¥çœ‹å‡ºï¼Œè¦æ£€æµ‹çš„å¯¹åº”å€¼æ¦‚ç‡è¶Šå¤§ï¼Œ-x[class]å°±å‡çš„è¶Šå¤šï¼Œè®¡ç®—å‡ºæ¥çš„æŸå¤±å°±è¶Šå°

![image-20230918170952717](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230918170952717.png)



```py
#åŠŸèƒ½ï¼šåˆ›å»ºä¸€ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼š
#ä¸€èˆ¬é»˜è®¤ä¸å¡«å‚æ•°
torch.nn.CrossEntropyLoss(weight=None, ignore_index=-100, reduction='mean', label_smoothing=0.0)
```

```py

loss = nn.CrossEntropyLoss()

tudui = Tudui()

for data in dataLoader:
    imgs, targets = data
    outputs = tudui(imgs)
    #è®¡ç®—æ¯ä¸ªbatch_sizeè¾“å‡ºå’Œæ ‡ç­¾çš„æŸå¤±
    result_loss = loss(outputs, tagets)
    print(result_loss)
```







#### [nn.Softmax()](https://blog.csdn.net/nefetaria/article/details/114411953?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169502603716800185890599%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169502603716800185890599&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-7-114411953-null-null.142^v94^insert_down28v1&utm_term=nn.Softmax%28%29&spm=1018.2226.3001.4187)

```py
tf.nn.softmax(
    logits, # è¾“å…¥ï¼šå…¨è¿æ¥å±‚ï¼ˆå¾€å¾€æ˜¯æ¨¡å‹çš„æœ€åä¸€å±‚ï¼‰çš„å€¼ï¼Œä¸€èˆ¬ä»£ç ä¸­å«åšlogits
    axis = None,
    name = None
    dim = None
)
```

ä½œç”¨ï¼šsoftmaxå‡½æ•°çš„ä½œç”¨å°±æ˜¯å½’ä¸€åŒ–ã€‚
è¾“å…¥ï¼šå…¨è¿æ¥å±‚ï¼ˆå¾€å¾€æ˜¯æ¨¡å‹çš„æœ€åä¸€å±‚ï¼‰çš„å€¼ï¼Œä¸€èˆ¬ä»£ç ä¸­å«åšlogits
è¾“å‡ºï¼šå½’ä¸€åŒ–çš„å€¼ï¼Œå«ä¹‰æ˜¯å±äºè¯¥ä½ç½®çš„æ¦‚ç‡ï¼Œä¸€èˆ¬ä»£ç å«åšprobs,ä¾‹å¦‚è¾“å‡º[0.4, 0.1, 0.2, 0.3],é‚£ä¹ˆè¿™ä¸ªæ ·æœ¬æœ€å¯èƒ½å±äºç¬¬0ä¸ªä½ç½®ï¼Œä¹Ÿå°±æ˜¯ç¬¬0ç±»ã€‚è¿™æ˜¯ç”±äºlogitsçš„ç»´åº¦å¤§å°å°±è®¾å®šçš„ä»»åŠ¡çš„ç±»åˆ«ï¼Œæ‰€ä»¥ç¬¬0ä¸ªä½ç½®å°±ä»£è¡¨ç¬¬0ç±»ã€‚softmaxå‡½æ•°çš„è¾“å‡ºä¸æ”¹å˜ç»´åº¦çš„å¤§å°ã€‚(è¯¥æ ·æœ¬å±äºå„ä¸ªç±»çš„æ¦‚ç‡)
ç”¨é€”ï¼šå¦‚æœåšå•åˆ†ç±»çš„é—®é¢˜ï¼Œé‚£ä¹ˆè¾“å‡ºçš„å€¼å°±å–top1(æœ€å¤§, argmax)ï¼› å¦‚æœåšå¤šåˆ†ç±»é—®é¢˜ï¼Œé‚£ä¹ˆè¾“å‡ºçš„å€¼å°±å–topNã€‚



### 4.6.4 [result_loss.backward()](https://blog.csdn.net/sinat_28731575/article/details/90342082?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169503593016800185840467%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169503593016800185840467&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-90342082-null-null.142^v94^insert_down28v1&utm_term=pytorch%20backword&spm=1018.2226.3001.4187)

å°†æŸå¤±losså‘è¾“å…¥æµ‹è¿›è¡Œåå‘ä¼ æ’­ï¼Œå¾—åˆ°æ¯ä¸ªtensorå†…éƒ¨è¦æ›´æ–°å‚æ•°(optimizer.step())å¯¹åº”çš„ä¸€ä¸ªæ¢¯åº¦å‚æ•°

```py
result_loss = loss(outputs, targets)
#ä½¿ç”¨åå‘ä¼ æ’­åŒæ—¶è®¡ç®—æ¢¯åº¦
result_loss.backward() #è¿™è¡Œè¿è¡Œå®Œåå°±ä¼šæ›´æ–°æ¨¡å‹å†…çš„grad
```



<img src="https://img-blog.csdnimg.cn/20210405102817343.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2NTEwMjQ1,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />



### 4.6.5 [torch.norm()](https://blog.csdn.net/qq_36556893/article/details/90698186?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169508938916800225511162%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169508938916800225511162&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-90698186-null-null.142^v94^insert_down28v1&utm_term=torch%20norm&spm=1018.2226.3001.4187)

`torch.norm()` æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè®¡ç®—è¾“å…¥å¼ é‡æ²¿æŒ‡å®šç»´åº¦çš„[èŒƒæ•°](https://so.csdn.net/so/search?q=èŒƒæ•°&spm=1001.2101.3001.7020)ã€‚å…·ä½“è€Œè¨€ï¼Œå½“ç»™å®šä¸€ä¸ªè¾“å…¥å¼ é‡ `x` å’Œä¸€ä¸ªæ•´æ•° `p` æ—¶ï¼Œ`torch.norm(x, p)` å°†è¿”å›è¾“å…¥å¼ é‡ `x` æ²¿ç€æœ€åä¸€ä¸ªç»´åº¦ï¼ˆé»˜è®¤ä¸ºæ‰€æœ‰ç»´åº¦ï¼‰ä¸Šæ‰€æœ‰å…ƒç´ çš„ `p` èŒƒæ•°ã€‚

[ä»€ä¹ˆæ˜¯èŒƒæ•°ï¼Ÿ](https://blog.csdn.net/zhaohongfei_358/article/details/122818616?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169503825316800188522280%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169503825316800188522280&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122818616-null-null.142^v94^insert_down28v1&utm_term=%E8%8C%83%E6%95%B0&spm=1018.2226.3001.4187)

```py
#å‚æ•°
def norm(input, p=2, dim=None, keepdim=False, out=None, dtype=None):
    
'''
inputï¼šè¾“å…¥tensorç±»å‹çš„æ•°æ®

pï¼šæŒ‡å®šçš„èŒƒæ•°ï¼Œé»˜è®¤ä¸ºp=â€˜froâ€™ï¼Œè®¡ç®—çŸ©é˜µçš„Frobenius norm (Frobenius èŒƒæ•°)ï¼Œå°±æ˜¯çŸ©é˜µå„é¡¹å…ƒç´ çš„ç»å¯¹å€¼å¹³æ–¹çš„æ€»å’Œã€‚
p='nucâ€™æ—¶ï¼Œ  æ˜¯æ±‚æ ¸èŒƒæ•°ï¼Œæ ¸èŒƒæ•°æ˜¯çŸ©é˜µå¥‡å¼‚å€¼çš„å’Œã€‚ï¼ˆä¸å¸¸ç”¨ï¼‰
pä¸ºintçš„å½¢å¼ï¼Œæ˜¯æ±‚p-èŒƒæ•°ã€‚ï¼ˆå¸¸ç”¨ï¼‰

dimï¼šæŒ‡å®šåœ¨å“ªä¸ªç»´åº¦è¿›è¡Œï¼Œå¦‚æœä¸æŒ‡å®šï¼Œåˆ™æ˜¯åœ¨æ‰€æœ‰ç»´åº¦è¿›è¡Œè®¡ç®—

keepdimï¼šTrue or Falseï¼Œå¦‚æœTrueï¼Œåˆ™ä¿ç•™dimæŒ‡å®šçš„ç»´åº¦ï¼ŒFalseåˆ™ä¸ä¿ç•™

outï¼šè¾“å‡ºçš„ tensor

dtypeï¼šæŒ‡å®šè¾“å‡ºçš„tensorçš„æ•°æ®ç±»å‹
'''
```

```py
tensor([[ 1.,  2.,  3.,  4.],
        [ 2.,  4.,  6.,  8.],
        [ 3.,  6.,  9., 12.]])

#æ¥ç€æˆ‘ä»¬åˆ†åˆ«å¯¹å…¶è¡Œå’Œåˆ—åˆ†åˆ«æ±‚2èŒƒæ•°
inputs1 = torch.norm(inputs, p=2, dim=1, keepdim=True) #è¡Œ
print(inputs1)
inputs2 = torch.norm(inputs, p=2, dim=0, keepdim=True) #åˆ—
print(inputs2)
#ç»“æœï¼š
tensor([[ 5.4772],
        [10.9545],
        [16.4317]])
tensor([[ 3.7417,  7.4833, 11.2250, 14.9666]])
```



### 4.6.6 ä¼˜åŒ–å™¨

#### 1 [torch.optim.SGD](https://blog.csdn.net/echo_gou/article/details/119536350?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169517442516800197019450%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169517442516800197019450&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-119536350-null-null.142^v94^insert_down28v1&utm_term=optim.SGD&spm=1018.2226.3001.4187)

å…¶ä¸­çš„SGDå°±æ˜¯optimä¸­çš„ä¸€ä¸ªç®—æ³•ï¼ˆä¼˜åŒ–å™¨ï¼‰ï¼š**éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•**

ä¸ºäº†ä½¿ç”¨torch.optimï¼Œä½ éœ€è¦æ„å»ºä¸€ä¸ªoptimizerå¯¹è±¡ã€‚è¿™ä¸ªå¯¹è±¡èƒ½å¤Ÿä¿æŒå½“å‰å‚æ•°çŠ¶æ€å¹¶åŸºäºè®¡ç®—å¾—åˆ°çš„æ¢¯åº¦è¿›è¡Œå‚æ•°æ›´æ–°ã€‚

```py
#å‚æ•°
optimizer = torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False, *, maximize=False, foreach=None, differentiable=False)
'''
lr (float) â€“ å­¦ä¹ ç‡
momentum (float, å¯é€‰) â€“ åŠ¨é‡å› å­ï¼ˆé»˜è®¤ï¼š0ï¼‰
weight_decay (float, å¯é€‰) â€“ æƒé‡è¡°å‡ï¼ˆL2æƒ©ç½šï¼‰ï¼ˆé»˜è®¤ï¼š0ï¼‰
dampening (float, å¯é€‰) â€“ åŠ¨é‡çš„æŠ‘åˆ¶å› å­ï¼ˆé»˜è®¤ï¼š0ï¼‰
nesterov (bool, å¯é€‰) â€“ ä½¿ç”¨NesterovåŠ¨é‡ï¼ˆé»˜è®¤ï¼šFalseï¼‰
'''

#ä¸€èˆ¬ä½¿ç”¨
tudui = Tudui()
#å­¦ä¹ ç‡å¤ªå°è·‘å¾—å¤ªæ…¢ï¼Œå¤ªå¤§æ—¶æ¨¡å‹è®­ç»ƒä¸ç¨³å®š
optimizer = torch.optim.SGD(tudui.parameters, lr=0.01)
```

##### [**ä¼˜åŒ–å™¨çš„å‡ ä¸ªæ–¹æ³•**](https://blog.csdn.net/weixin_43863869/article/details/128120719?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169517544416800192260220%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169517544416800192260220&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-128120719-null-null.142^v94^insert_down28v1&utm_term=optimizer.zero_grad%28%29%E7%9A%84%E4%BD%9C%E7%94%A8&spm=1018.2226.3001.4187)

```py
optimizer.step()
'''
ä½œç”¨ï¼šåˆ©ç”¨ä¼˜åŒ–å™¨å¯¹å‚æ•°xè¿›è¡Œè°ƒä¼˜ï¼Œä»¥éšæœºæ¢¯åº¦ä¸‹é™SGDä¸ºä¾‹ï¼Œæ›´æ–°çš„å…¬å¼ä¸ºï¼šx=xâˆ’lrâˆ—(xâˆ—grad)
ï¼Œlr è¡¨ç¤ºå­¦ä¹ ç‡ lr ï¼Œå‡å·è¡¨ç¤ºæ²¿ç€æ¢¯åº¦çš„åæ–¹å‘è¿›è¡Œæ›´æ–°ï¼›
'''

optimizer.zero_grad()
'''
ä½œç”¨ï¼šæ¸…0ä¼˜åŒ–å™¨å…³äºæ‰€æœ‰å‚æ•°xçš„ç´¯è®¡æ¢¯åº¦å€¼ xâˆ—grad
ï¼Œä¸€èˆ¬åœ¨loss.backward()å‰ä½¿ç”¨
'''
```

ä¸€æ¬¡å®Œæ•´çš„é’ˆå¯¹CIFAR10çš„æ¨¡å‹è®­ç»ƒï¼Œå¯¹æ¯æ¬¡è®­ç»ƒè¿­ä»£è¿›è¡ŒæŸå¤±çš„è®¡ç®—

```py
import torch
import torchvision
from torch import nn
from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear
#å¼•å…¥æ•°æ®é›†å’Œå¤„ç†å™¨
dataset = torchvision.datasets.CIFAR10('./dataset', train=False,
                                         transform=torchvision.transforms.ToTensor(), download=True)
dataLoader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1)

#åˆ›å»ºæ¨¡å‹
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        )

    def forward(self, x):
        x = self.model(x)
        return x


tudui = Tudui()
loss = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(tudui.parameters(), lr=0.01)

#å¼€å§‹è®­ç»ƒ
for epoch in range(3):
    sum_loss = 0.0
    for data in dataLoader:
        imgs, targets = data
        outputs = tudui.forward(imgs)
        #è®¡ç®—æŸå¤±
        result_loss = loss(outputs, targets)
        #optimizer.zero_grad() ä½œç”¨ï¼šæ¸…é™¤ä¹‹å‰ç§¯ç´¯çš„æ¢¯åº¦
        # ä¸€èˆ¬åœ¨loss.backward()å‰ä½¿ç”¨ï¼Œå³æ¸…é™¤ (xâˆ—grad)pre
        optimizer.zero_grad()
        #åå‘ä¼ æ’­ï¼Œæ›´æ–°æ¢¯åº¦
        result_loss.backward()
        #å¯¹æ¯ä¸ªå‚æ•°è¿›è¡Œè°ƒä¼˜
        optimizer.step()
        sum_loss += result_loss
    print(sum_loss)
```

```py
#è¾“å‡º
C:\Users\1\miniconda3\envs\pytorchlearn\python.exe D:\pycharmProjects\pytorchlearn\nn_optim.py 
Files already downloaded and verified
tensor(18721.0879, grad_fn=<AddBackward0>)
tensor(16111.2578, grad_fn=<AddBackward0>)
tensor(15386.7744, grad_fn=<AddBackward0>)
```

### 4.6.7 torchvision.models

#### 1  VGG(å¸¸ç”¨ï¼šVGG16/19)

##### åˆ›å»ºæ¨¡å‹

```py
torchvision.models.vgg16(*, weights: Optional[VGG16_Weights] = None, progress: bool = True, **kwargs: Any) â†’ VGG
'''
weights:è¦ä½¿ç”¨çš„è®­ç»ƒæƒé‡,è‹¥ä¸ä½¿ç”¨é¢„è®­ç»ƒï¼Œåˆ™å¡«ä¸€ä¸ªweight=Noneï¼Œè‹¥è¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™ç”¨é»˜è®¤(weight='VGG16_Weights.DEFAULT')
progressï¼šå¦‚æœä¸ºTrueï¼Œåˆ™æ˜¾ç¤ºä¸‹è½½åˆ°æ ‡å‡†ç¨‹åºçš„è¿›åº¦æ¡ã€‚é»˜è®¤ä¸ºTrue
ä¸€èˆ¬å¡«è¿™ä¸¤ä¸ªå°±è¡Œ
'''
```

```py
vgg16_true = torchvision.models.vgg16( weights='DEFAULT')

vgg16_false = torchvision.models.vgg16(weights=None)

print(vgg16_true)
#---------------------------------------------------------
VGG(
  #æå–ç‰¹å¾
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  #map_location=torch.device('cpu')ï¼Œæ„æ€æ˜¯æ˜ å°„åˆ°cpuä¸Šï¼Œåœ¨cpuä¸ŠåŠ è½½æ¨¡å‹ï¼Œæ— è®ºä½ è¿™ä¸ªæ¨¡å‹ä»å“ªé‡Œè®­ç»ƒä¿å­˜çš„ï¼Œä¸»è¦æ˜¯æ”¹å˜åˆ†è¾¨ç‡
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  #åˆ†ç±»å™¨ï¼Œé¢„æµ‹ç”¨
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
```

##### **ä¿®æ”¹æ¨¡å‹**

```py
#å¯¹ç°æœ‰æ¨¡å‹æ·»åŠ å±‚
vgg16_true.classifier.add_module('add_Linear', nn.Linear(1000, 10))
print(vgg16_true)
---------------------------------------------
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
    (add_Linear): Linear(in_features=1000, out_features=10, bias=True) #-->æ·»åŠ äº†ä¸€å±‚
  )

#å¯¹ç°æœ‰æ¨¡å‹ä¿®æ”¹å±‚
vgg16_false.classifier[6] = nn.Linear(4096, 10)
print(vgg16_false)
----------------------------------------------
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True) #-->è¢«ä¿®æ”¹äº†
  )
```

##### ä¿å­˜æ¨¡å‹

```py
vgg16 = torchvision.models.vgg16(weights=None)

#ä¿å­˜æ–¹å¼ä¸€
torch.save(vgg16, 'vgg16_method1.pth')

#ä¿å­˜æ–¹å¼äºŒï¼šä»¥å­—å…¸çš„å½¢å¼ä¿å­˜
torch.save(vgg16.state_dict(), 'vgg16_method2.pth')
```

##### [åŠ è½½æ¨¡å‹](https://blog.csdn.net/pearl8899/article/details/109566084?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169529774616800192295944%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169529774616800192295944&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-109566084-null-null.142^v94^insert_down28v1&utm_term=torch.load&spm=1018.2226.3001.4187)

```py
#æ–¹å¼ä¸€
model1 = torch.load('vgg16_method1.pth')
# print(model1)

#æ–¹å¼äºŒ:ä»¥å­—å…¸æ–¹å¼åŠ è½½
map_location=torch.device('cpu') #æ„æ€æ˜¯æ˜ å°„åˆ°cpuä¸Šï¼Œåœ¨cpuä¸ŠåŠ è½½æ¨¡å‹ï¼Œæ— è®ºä½ è¿™ä¸ªæ¨¡å‹ä»å“ªé‡Œè®­ç»ƒä¿å­˜çš„
model2 = torch.load('vgg16_method2.pth')
print(model2)

#æ–¹å¼äºŒï¼šåŠ è½½æ¨¡å‹
vgg16 = torchvision.models.vgg16(weights=None)
vgg16.load_state_dict(torch.load('vgg16_method2.pth'))
#è¿™æ ·å°±èƒ½æŠŠdictå­˜å‚¨çš„æ¨¡å‹è½¬å›åŸæ¥çš„æ–¹å¼è¾“å‡º
print(vgg16)
```

#### 2 model.train()/eval()



## 4.7 opencv

```py
#windowsä½¿ç”¨pipå®‰è£…
pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple
```



# 5 é—®é¢˜

## 5.1 pythoné—®é¢˜

### 5.1.1 [pythonæ•°æ®è¯»å–è·¯å¾„ä¸ºå•¥è¦ç”¨åŒåæ–œæ ?](https://www.cnblogs.com/zwt20120701/p/11267457.html)

### 5.1.2 [r'å­—ç¬¦ä¸²'æ˜¯ä»€ä¹ˆæ„æ€]([Pythonä¸­çš„rå­—ç¬¦ä¸²å‰ç¼€åŠå…¶ç”¨æ³•è¯¦è§£_python å­—ç¬¦ä¸²å‰å¸¦r_å¿µå¹¿éš¶çš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/lsoxvxe/article/details/132001495?ops_request_misc=%7B%22request%5Fid%22%3A%22169405062216777224494582%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&request_id=169405062216777224494582&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-132001495-null-null.142^v93^insert_down28v1&utm_term=python rå­—ç¬¦ä¸²&spm=1018.2226.3001.4187))

### 5.1.3 Pythonä¹Ÿæœ‰æ•°ç»„ï¼Œä¸ºä»€ä¹ˆè¦ç”¨Numpyï¼Ÿ

Pythonä¸­æä¾›äº†listå®¹å™¨ï¼Œå¯ä»¥å½“ä½œæ•°ç»„ä½¿ç”¨ã€‚ä½†åˆ—è¡¨ä¸­çš„å…ƒç´ å¯ä»¥æ˜¯ä»»ä½•å¯¹è±¡ï¼Œå› æ­¤åˆ—è¡¨ä¸­ä¿å­˜çš„æ˜¯å¯¹è±¡çš„æŒ‡é’ˆï¼Œè¿™æ ·ä¸€æ¥ï¼Œä¸ºäº†ä¿å­˜ä¸€ä¸ªç®€å•çš„åˆ—è¡¨[1,2,3]ã€‚å°±éœ€è¦ä¸‰ä¸ªæŒ‡é’ˆå’Œä¸‰ä¸ªæ•´æ•°å¯¹è±¡ã€‚å¯¹äºæ•°å€¼è¿ç®—æ¥è¯´ï¼Œè¿™ç§ç»“æ„æ˜¾ç„¶ä¸å¤Ÿé«˜æ•ˆã€‚
Pythonè™½ç„¶ä¹Ÿæä¾›äº†arrayæ¨¡å—ï¼Œä½†å…¶åªæ”¯æŒä¸€ç»´æ•°ç»„ï¼Œä¸æ”¯æŒå¤šç»´æ•°ç»„ï¼Œä¹Ÿæ²¡æœ‰å„ç§è¿ç®—å‡½æ•°ã€‚å› è€Œä¸é€‚åˆæ•°å€¼è¿ç®—ã€‚
Numpyå†…ç½®ä¸°å¯Œçš„æ–¹æ³•ï¼Œèƒ½æ›´åŠ è½»æ¾é«˜æ•ˆåœ°è¿›è¡Œç§‘å­¦è®¡ç®—ã€‚

### 5.1.4 ä½¿ç”¨å„ç±»æ–¹æ³•çš„æ³¨æ„

å…³äºä½¿ç”¨å„ç±»å‡½æ•°æ—¶çš„æ³¨æ„ç‚¹ï¼šè‹¥å£°æ˜å¤„æœ‰é»˜è®¤å€¼ï¼Œä¸€èˆ¬ä¸åŠ¨ï¼Œå¡«å‚æ•°æ—¶åªéœ€å¡«æ²¡æœ‰é»˜è®¤å€¼çš„å€¼å°±å¯ä»¥äº†

ä¸çŸ¥é“æ–°å‡½æ•°çš„è¿”å›å€¼æ—¶ï¼Œä»¥ä¸‹å‡ ç§æ€è·¯ï¼š

> print
>
> print(type(...))
>
> debug
>
> ä¸Šç½‘æŸ¥

### 5.1.5 å®šä¹‰ç±»æ—¶å¯ä»¥ç›´æ¥ä½¿ç”¨self.xxä»£æ›¿å˜é‡çš„å£°æ˜



## 5.2 æ•°å­¦é—®é¢˜

### 5.2.1 [èŒƒæ•°](https://blog.csdn.net/weixin_42066990/article/details/118636995?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169508767416800188597670%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169508767416800188597670&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-118636995-null-null.142^v94^insert_down28v1&utm_term=%E8%8C%83%E6%95%B0%E6%98%AF%E4%BB%80%E4%B9%88&spm=1018.2226.3001.4187)

å®ƒå¸¸å¸¸è¢«ç”¨æ¥åº¦é‡æŸä¸ªå‘é‡ç©ºé—´ï¼ˆæˆ–çŸ©é˜µï¼‰ä¸­çš„æ¯ä¸ªå‘é‡çš„é•¿åº¦æˆ–å¤§å°ã€‚



# 6 aiç†è®º

## 6.1 [æ·±åº¦å­¦ä¹ -å›¾åƒåŸºç¡€](https://blog.csdn.net/weixin_44211968/article/details/123876506?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169459167716800222837715%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169459167716800222837715&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-123876506-null-null.142^v93^insert_down28v1&utm_term=%E5%9B%BE%E5%83%8F%E9%80%9A%E9%81%93&spm=1018.2226.3001.4187)

å›¾ç‰‡å¯ä»¥çœ‹ä½œæ˜¯ **ä¸‰å±‚** **äºŒç»´æ•°ç»„** çš„å åŠ ï¼Œæ¯ä¸€å±‚äºŒç»´æ•°ç»„éƒ½æ˜¯ä¸€ä¸ªé€šé“ã€‚å•é€šé“çš„å›¾åƒæ˜¯ç°è‰²çš„ï¼Œæ¯ä¸ªåƒç´ pixelåªæœ‰ä¸€ä¸ªvalueï¼Œæ•°å­—è¶Šé«˜ï¼Œé¢œè‰²è¶Šç™½ï¼Œä¹Ÿå°±è¶Šäº®ã€‚å³ä¸‰é€šé“ï¼Œæ¯ä¸ªé€šé“ç”±äºŒç»´æ•°ç»„å­˜å‚¨ã€‚

ä¸‰å±‚çš„ value åˆ†åˆ«ä»£è¡¨ç€è¿™ä¸ªç‚¹åœ¨ä¸‰ä¸ªé€šé“çš„æ•°å€¼ï¼Œè®¡ç®—æœºæ ¹æ®è¿™äº›æ•°å€¼æ¥ç¡®å®šè¿™ä¸€ä¸ªåƒç´ ç‚¹çš„é¢œè‰²ã€‚è¿™å°±å¸¸è§çš„ä¸‰å±‚ RGB è‰²å½©ç©ºé—´çš„å·¥ä½œæ–¹å¼ã€‚

RGB æ ¼å¼é‡Œ(0,0,0)ä»£è¡¨ç€é»‘è‰²ï¼Œ(255,255,255)ä»£è¡¨ç€ç™½è‰²ã€‚

æ³¨æ„: OpenCV(å¼€æºè®¡ç®—æœºè§†è§‰åº“ï¼ŒåŒ…å«äº†è®¸å¤šå¯ç”¨çš„è§†è§‰ç®—æ³•ï¼Œå›¾åƒå¤„ç†å¿…å¤‡ç¥å™¨)å›¾åƒé€šé“çš„**é»˜è®¤æ’åºæ˜¯ BGR**ã€‚



## 6.2 [å½’ä¸€åŒ–ï¼ˆnormalizationï¼‰](https://blog.csdn.net/yangbindxj/article/details/125294045?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169448177316800215060118%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169448177316800215060118&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-125294045-null-null.142^v93^insert_down28v1&utm_term=%E5%BD%92%E4%B8%80%E5%8C%96&spm=1018.2226.3001.4187&ydreferer=aHR0cHM6Ly9zby5jc2RuLm5ldC9zby9zZWFyY2g%2Fc3BtPTEwMDEuMjEwMS4zMDAxLjQ0OTgmcT0lRTUlQkQlOTIlRTQlQjglODAlRTUlOEMlOTYmdD0mdT0%3D)

**å½’ä¸€åŒ–å°±æ˜¯è¦æŠŠå›¾ç‰‡3ä¸ªé€šé“ä¸­çš„æ•°æ®æ•´ç†åˆ°[-1, 1]åŒºé—´**

ä¸ºäº†æ¶ˆé™¤æŒ‡æ ‡ä¹‹é—´çš„é‡çº²å½±å“ï¼Œéœ€è¦è¿›è¡Œ[æ•°æ®æ ‡å‡†åŒ–å¤„ç†](https://so.csdn.net/so/search?q=æ•°æ®æ ‡å‡†åŒ–å¤„ç†&spm=1001.2101.3001.7020)ï¼Œä»¥è§£å†³æ•°æ®æŒ‡æ ‡ä¹‹é—´çš„å¯æ¯”æ€§ã€‚åŸå§‹æ•°æ®ç»è¿‡æ•°æ®æ ‡å‡†åŒ–å¤„ç†åï¼Œå„æŒ‡æ ‡å¤„äºåŒä¸€æ•°é‡çº§ï¼Œé€‚åˆè¿›è¡Œç»¼åˆå¯¹æ¯”è¯„ä»·ã€‚å…¶ä¸­ï¼Œæœ€å…¸å‹çš„å°±æ˜¯æ•°æ®çš„å½’ä¸€åŒ–å¤„ç†ã€‚

**ç®€è€Œè¨€ä¹‹ï¼Œå½’ä¸€åŒ–çš„ç›®çš„å°±æ˜¯ä½¿å¾—é¢„å¤„ç†çš„æ•°æ®è¢«é™å®šåœ¨ä¸€å®šçš„èŒƒå›´å†…ï¼ˆæ¯”å¦‚[0,1]æˆ–è€…[-1,1]ï¼‰ï¼Œä»è€Œæ¶ˆé™¤å¥‡å¼‚æ ·æœ¬æ•°æ®å¯¼è‡´çš„ä¸è‰¯å½±å“ã€‚**

![img](D:\Learn\python-code-note\assets\3e6e5ae01efdc6e97353275439b307de.png)

**å¥‡å¼‚æ ·æœ¬æ•°æ®çš„å­˜åœ¨ä¼šå¼•èµ·è®­ç»ƒæ—¶é—´å¢å¤§ï¼ŒåŒæ—¶ä¹Ÿå¯èƒ½å¯¼è‡´æ— æ³•æ”¶æ•›ï¼Œå› æ­¤ï¼Œå½“å­˜åœ¨å¥‡å¼‚æ ·æœ¬æ•°æ®æ—¶ï¼Œåœ¨è¿›è¡Œè®­ç»ƒä¹‹å‰éœ€è¦å¯¹é¢„å¤„ç†æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼›åä¹‹ï¼Œä¸å­˜åœ¨å¥‡å¼‚æ ·æœ¬æ•°æ®æ—¶ï¼Œåˆ™å¯ä»¥ä¸è¿›è¡Œå½’ä¸€åŒ–ã€‚**

**å½’ä¸€åŒ–çš„å¯¹æ¯”**

--å¦‚æœä¸è¿›è¡Œå½’ä¸€åŒ–ï¼Œé‚£ä¹ˆç”±äºç‰¹å¾å‘é‡ä¸­ä¸åŒç‰¹å¾çš„å–å€¼ç›¸å·®è¾ƒå¤§ï¼Œä¼šå¯¼è‡´ç›®æ ‡å‡½æ•°å˜â€œæ‰â€ã€‚è¿™æ ·åœ¨è¿›è¡Œæ¢¯åº¦ä¸‹é™çš„æ—¶å€™ï¼Œæ¢¯åº¦çš„æ–¹å‘å°±ä¼šåç¦»æœ€å°å€¼çš„æ–¹å‘ï¼Œèµ°å¾ˆå¤šå¼¯è·¯ï¼Œå³è®­ç»ƒæ—¶é—´è¿‡é•¿ã€‚



## 6.3 [HWCå’ŒCHW](https://blog.csdn.net/hh1357102/article/details/130622666?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169459146616800227429193%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169459146616800227429193&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-130622666-null-null.142^v93^insert_down28v1&utm_term=RGB%E5%9B%BE%E5%83%8F%E7%9A%84%E5%AD%98%E5%82%A8&spm=1018.2226.3001.4187)

### 6.3.1 HWC

**HWCå¯ä»¥çœ‹ä½œæ˜¯ä¸€å¹…å›¾åƒçš„shape**ï¼ŒHè¡¨ç¤ºå›¾åƒçš„é«˜åº¦(height)ï¼ŒWè¡¨ç¤ºå›¾åƒçš„å®½åº¦(Width)ï¼Œè€ŒCè¡¨ç¤ºä¸€å¹…å›¾åƒçš„é€šé“æ•°(Channel)ã€‚HWCæ ¼å¼æ˜¯æŒ‡æŒ‰ç…§é«˜åº¦ã€å®½åº¦å’Œé€šé“æ•°çš„é¡ºåºæ’åˆ—å›¾åƒå°ºå¯¸çš„æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œä¸€å¼ å½¢çŠ¶ä¸º256Ã—256Ã—3çš„RGBå›¾åƒï¼Œåœ¨HWCæ ¼å¼ä¸­è¡¨ç¤ºä¸º[256, 256, 3]ã€‚åœ¨ä¸€äº›å›¾åƒå¤„ç†åº“æˆ–è€…åº•å±‚æ¡†æ¶ä¸­ï¼Œä¾‹å¦‚**OpenCVå’ŒTensorFlowï¼Œé€šå¸¸ä½¿ç”¨HWCæ ¼å¼è¡¨ç¤ºå›¾åƒå°ºå¯¸ã€‚**

åœ¨OpenCVä¸­ï¼Œè¯»å–çš„å›¾ç‰‡é»˜è®¤æ˜¯HWCæ ¼å¼

**ä¸¾ä¸ªå°æ —å­**

hwc=[5,5,3] çš„å«ä¹‰æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

å¤§å®¶å¯ä»¥æ€è€ƒä¸€ä¸‹ï¼Œä»¥å›¾åƒä¸ºä¾‹ï¼Œé‚£ä¹ˆé«˜å®½éƒ½æ˜¯5ï¼Œ3å°±æ˜¯å…¶ä¸­çš„é€šé“æ•°ã€‚å› æ­¤æˆ‘ä»¬ä¹Ÿå¯ä»¥ç†è§£ä¸º***\*3ä¸ª 5\*5 å¤§å°çš„ç‰¹å¾å›¾\****ã€‚ 



### 6.3.2 CHW

CHWæ ¼å¼æ˜¯æŒ‡æŒ‰ç…§é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦çš„é¡ºåºæ’åˆ—å›¾åƒå°ºå¯¸çš„æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œä¸€å¼ å½¢çŠ¶ä¸º3Ã—256Ã—256çš„RGBå›¾åƒï¼Œåœ¨CHWæ ¼å¼ä¸­è¡¨ç¤ºä¸º[3, 256, 256]ã€‚**åœ¨è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ ä¸­å¦‚pytorchï¼Œé€šå¸¸ä½¿ç”¨CHWæ ¼å¼è¡¨ç¤ºå›¾åƒå°ºå¯¸ã€‚**

ä¾‹å¦‚ï¼Œä¸€ä¸ª2x2çš„RGBå›¾åƒåœ¨CHWæ ¼å¼ä¸‹å¯èƒ½ä¼šä»¥ä»¥ä¸‹æ–¹å¼è½¬ä¸ºä¸€ç»´æ•°ç»„ï¼š

```py
åŸå§‹çš„CHWæ ¼å¼è¡¨ç¤ºä¸ºï¼š
[
    [[R11, R12], [R21, R22]],
    [[G11, G12], [G21, G22]],
    [[B11, B12], [B21, B22]]
]
è¡Œä¼˜å…ˆæ‰å¹³åŒ–åçš„ä¸€ç»´è¡¨ç¤ºä¸ºï¼š
[R11, R12, R21, R22, G11, G12, G21, G22, B11, B12, B21, B22]
```

#### ä¸ºä»€ä¹ˆpytorchä¸­transforms.ToTorchè¦æŠŠ(H,W,C)çš„çŸ©é˜µè½¬ä¸º(C,H,W)? 

- å› ä¸ºpytorchå¾ˆå¤šå‡½æ•°éƒ½æ˜¯è®¾è®¡æˆå‡è®¾ä½ çš„è¾“å…¥æ˜¯ ï¼ˆcï¼Œhï¼Œwï¼‰çš„æ ¼å¼ï¼Œå½“ç„¶ä½ å¦‚æœä¸å«Œéº»çƒ¦çš„è¯å¯ä»¥æ¯æ¬¡è¦ç”¨è¿™äº›å‡½æ•°çš„æ—¶å€™è½¬æˆchwæ ¼å¼ï¼Œä½†æˆ‘æƒ³è¿™ä¼šæ¯”ä½ è¾“å…¥çš„æ—¶å€™å°±è½¬æˆchwè¦éº»çƒ¦å¾ˆå¤šã€‚
- è‡³äºä¸ºä»€ä¹ˆpytorché€‰æ‹©è®¾è®¡æˆchwè€Œä¸æ˜¯hwcï¼ˆæ¯•ç«Ÿä¼ ç»Ÿçš„è¯»å›¾ç‰‡çš„å‡½æ•°opencvçš„cv2.imreadæˆ–è€…sklearnçš„imreadéƒ½æ˜¯è¯»æˆhwcçš„æ ¼å¼çš„ï¼‰è¿™ç‚¹ç¡®å®æ¯”è¾ƒä»¤åˆå­¦è€…å›°æƒ‘ã€‚ä¸ªäººæ„Ÿè§‰æ˜¯å› ä¸ºpytorchåšçŸ©é˜µåŠ å‡ä¹˜é™¤ä»¥åŠå·ç§¯ç­‰è¿ç®—æ˜¯éœ€è¦è°ƒç”¨cudaå’Œcudnnçš„å‡½æ•°çš„ï¼Œè€Œè¿™äº›æ¥å£éƒ½è®¾æˆæˆchwæ ¼å¼äº†ï¼Œæ•…è€Œpytorchä¸ºäº†æ–¹ä¾¿èµ·è§ä¹Ÿè®¾è®¡æˆchwæ ¼å¼äº†ã€‚
- é‚£æ–°é—®é¢˜å°±æ¥äº†ï¼Œcudaå’Œcudnnä¸ºä»€ä¹ˆè®¾è®¡æˆchwæ ¼å¼å‘¢ï¼Ÿæˆ‘æƒ³è¿™æ˜¯ç”±äºæ¶‰åŠåˆ°å›¾ç‰‡æ“ä½œçš„éƒ½æ˜¯å’Œå·ç§¯ç›¸å…³çš„ï¼Œè€Œå†…éƒ¨åšå·ç§¯è¿ç®—çš„åŠ é€Ÿè®¾è®¡æˆchwåœ¨æ“ä½œä¸Šä¼šæ¯”hwcå¤„ç†èµ·æ¥æ›´å®¹æ˜“ï¼Œæ›´å¿«ã€‚é¢˜ä¸»å¦‚æœæƒ³è¿›ä¸€æ­¥äº†è§£å¯ä»¥googleä¸€ä¸‹cudnnçš„å·ç§¯å®ç°ã€‚



#### Torchå°†HWCæ ¼å¼è½¬ä¸ºCHW

```py
from PIL import Image
from torchvision.transforms import ToTensor
 
img = Image.open('image_path')
#äº§ç”Ÿçš„PIL_imageæ ¼å¼æ•°æ®çš„å–å€¼èŒƒå›´æ˜¯[0,255]
#å½¢çŠ¶(shape)æ˜¯[h, w, c]
#åƒç´ é¡ºåºæ˜¯RGB
 
tensor = ToTensor()(PIL_img)
 	
# æˆ–è€…
np_data = np.asarray(PIL_img)
tensor = ToTensor()(np_data)
```



## 6.4 ç¥ç»ç½‘ç»œæ¶æ„

### 6.4.1 å·ç§¯Convolution





### 6.4.2 æ± åŒ–Pooling

åœ¨æ¨¡ç³Šçš„åŒæ—¶å°½é‡çš„ä¿ç•™äº†åŸå§‹å›¾ç‰‡çš„ä¿¡æ¯



### 6.4.3 éçº¿æ€§æ¿€æ´»

â€‚â€‚â€‚â€‚å¦‚æœ[ç¥ç»å…ƒ](https://so.csdn.net/so/search?q=ç¥ç»å…ƒ&spm=1001.2101.3001.7020)çš„è¾“å‡ºæ˜¯è¾“å…¥çš„çº¿æ€§å‡½æ•°ï¼Œè€Œçº¿æ€§å‡½æ•°ä¹‹é—´çš„åµŒå¥—ä»»ç„¶ä¼šå¾—åˆ°çº¿æ€§å‡½æ•°ã€‚å¦‚æœä¸åŠ éçº¿æ€§å‡½æ•°å¤„ç†ï¼Œé‚£ä¹ˆæœ€ç»ˆå¾—åˆ°çš„ä»ç„¶æ˜¯çº¿æ€§å‡½æ•°ã€‚æ‰€ä»¥éœ€è¦åœ¨ç¥ç»ç½‘ç»œä¸­å¼•å…¥éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚åœ¨[äººå·¥ç¥ç»ç½‘ç»œ](https://so.csdn.net/so/search?q=äººå·¥ç¥ç»ç½‘ç»œ&spm=1001.2101.3001.7020)ä¸­ï¼Œæ¿€æ´»å‡½æ•°å†³å®šæ˜¯å¦éœ€è¦ä¼ é€’ä¿¡å·ã€‚

![image-20230918104945081](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230918104945081.png)

![image-20230918104955808](./æ·±åº¦å­¦ä¹ ç¬”è®°.assets/image-20230918104955808.png)

â€‹	é€šè¿‡å¯¹æ¯”éçº¿æ€§æ“ä½œå‰åçš„å›¾åƒï¼Œå‘ç°ç»è¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°å¤„ç†ä¹‹åçš„å›¾åƒä¸­çš„ä¸»è¦å†…å®¹æ›´çªå‡ºäº†ã€‚
â€‚â€‚â€‚â€‚ReLUå‡½æ•°å¤„ç†è‡ªç„¶è¯­è¨€æ•ˆæœæ›´ä½³ï¼ŒSigmoidå‡½æ•°å¤„ç†å›¾åƒæ•ˆæœæ›´ä½³ã€‚

### 6.4.4 Dropoutå±‚

dropoutæ˜¯ä½¿æŒ‡å®šæ¦‚ç‡çš„æƒé‡éšæœºå¤±æ´»ï¼Œä½œç”¨æ˜¯åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œæµ‹è¯•çš„æ—¶å€™æ˜¯ä¸ç”¨çš„



## 6.5 ç†µ

### 6.5.1 ç†µ

é‚£ä¹ˆç†µçš„é‚£äº›æè¿°å’Œè§£é‡Š(æ··ä¹±ç¨‹åº¦ï¼Œä¸ç¡®å®šæ€§ï¼ŒæƒŠå¥‡ç¨‹åº¦ï¼Œä¸å¯é¢„æµ‹æ€§ï¼Œä¿¡æ¯é‡ç­‰)ä»£è¡¨äº†ä»€ä¹ˆå‘¢ï¼Ÿ

å¦‚æœç†µæ¯”è¾ƒå¤§(å³å¹³å‡ç¼–ç é•¿åº¦è¾ƒé•¿)ï¼Œæ„å‘³ç€è¿™ä¸€ä¿¡æ¯æœ‰è¾ƒå¤šçš„å¯èƒ½çŠ¶æ€ï¼Œç›¸åº”çš„æ¯ä¸ªçŠ¶æ€çš„å¯èƒ½æ€§æ¯”è¾ƒä½ï¼›å› æ­¤æ¯å½“æ¥äº†ä¸€ä¸ªæ–°çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¾ˆéš¾å¯¹å…¶ä½œå‡ºå‡†ç¡®é¢„æµ‹ï¼Œå³æœ‰ç€æ¯”è¾ƒå¤§çš„æ··ä¹±ç¨‹åº¦/ä¸ç¡®å®šæ€§/ä¸å¯é¢„æµ‹æ€§ã€‚

å¹¶ä¸”å½“ä¸€ä¸ªç½•è§çš„ä¿¡æ¯åˆ°è¾¾æ—¶ï¼Œæ¯”ä¸€ä¸ªå¸¸è§çš„ä¿¡æ¯æœ‰ç€æ›´å¤šçš„ä¿¡æ¯é‡ï¼Œå› ä¸ºå®ƒæ’é™¤äº†åˆ«çš„å¾ˆå¤šçš„å¯èƒ½æ€§ï¼Œå‘Šè¯‰äº†æˆ‘ä»¬ä¸€ä¸ªç¡®åˆ‡çš„ä¿¡æ¯ã€‚åœ¨å¤©æ°”çš„ä¾‹å­ä¸­ï¼ŒRainyå‘ç”Ÿçš„æ¦‚ç‡ä¸º12.5%ï¼Œå½“æ¥æ”¶åˆ°è¯¥ä¿¡æ¯æ—¶ï¼Œæˆ‘ä»¬å‡å°‘äº†87.5%çš„ä¸ç¡®å®šæ€§(Fine,Cloudy,Snow)ï¼›å¦‚æœæ¥æ”¶åˆ°Fine(50%)çš„æ¶ˆæ¯ï¼Œæˆ‘ä»¬åªå‡å°‘äº†50%çš„ä¸ç¡®å®šæ€§ã€‚

### 6.5.2 [äº¤å‰ç†µï¼ˆåœ¨åˆ†ç±»é—®é¢˜ä¸­å¸¸è§çš„æŸå¤±å‡½æ•°ï¼‰](https://blog.csdn.net/Yue_Zengying/article/details/117111510?ops_request_misc=&request_id=&biz_id=102&utm_term=%E4%BA%A4%E5%8F%89%E7%86%B5&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-9-117111510.142^v94^insert_down28v1&spm=1018.2226.3001.4187)

å‡è®¾æœ‰ä¸¤ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹å¯¹ç¬¬ä¸€å¼ ç…§ç‰‡åˆ†åˆ«ä½œå‡ºäº†é¢„æµ‹ï¼šQ1å’ŒQ2,è€Œç¬¬ä¸€å¼ ç…§ç‰‡çš„çœŸå®æ ‡ç­¾ä¸º[1,0,0,0,0]ã€‚![img](https://img-blog.csdnimg.cn/202105211147578.png#pic_center)

ä¸¤ä¸ªæ¨¡å‹é¢„æµ‹æ•ˆæœå¦‚ä½•å‘¢ï¼Œå¯ä»¥åˆ†åˆ«è®¡ç®—ä¸‹äº¤å‰ç†µï¼š

<img src="https://img-blog.csdnimg.cn/20210521114815834.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1l1ZV9aZW5neWluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="img" style="zoom:67%;" />

äº¤å‰ç†µå¯¹æ¯”äº†æ¨¡å‹çš„é¢„æµ‹ç»“æœå’Œæ•°æ®çš„çœŸå®æ ‡ç­¾ï¼Œéšç€é¢„æµ‹è¶Šæ¥è¶Šå‡†ç¡®ï¼Œäº¤å‰ç†µçš„å€¼è¶Šæ¥è¶Šå°ï¼Œå¦‚æœé¢„æµ‹å®Œå…¨æ­£ç¡®ï¼Œäº¤å‰ç†µçš„å€¼å°±ä¸º0ã€‚å› æ­¤ï¼Œè®­ç»ƒåˆ†ç±»æ¨¡å‹æ—¶ï¼Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°ã€‚

### 6.5.3 äºŒåˆ†ç±»äº¤å‰ç†µ

åœ¨äºŒåˆ†ç±»æ¨¡å‹ä¸­ï¼Œæ ‡ç­¾åªæœ‰æ˜¯å’Œå¦ä¸¤ç§ï¼›è¿™æ—¶ï¼Œå¯ä»¥ä½¿ç”¨äºŒåˆ†ç±»äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°ã€‚å‡è®¾æ•°æ®é›†ä¸­åªæœ‰çŒ«å’Œç‹—çš„ç…§ç‰‡ï¼Œåˆ™äº¤å‰ç†µå…¬å¼ä¸­åªåŒ…å«ä¸¤ç§å¯èƒ½æ€§ï¼š![img](https://img-blog.csdnimg.cn/202105211150414.jpg#pic_center)

è€ŒP(cat) = 1 - P(dog)
æ‰€ä»¥äº¤å‰ç†µå¯ä»¥è¡¨ç¤ºä¸ºï¼š
H(P,Q)=-P(cat)logQ(cat)-(1-P(cat))log(1-Q(cat))
ä½¿ç”¨å¦‚ä¸‹å®šä¹‰ï¼š

![img](https://img-blog.csdnimg.cn/20210521115229397.png#pic_center)

äºŒåˆ†ç±»çš„äº¤å‰ç†µå¯ä»¥å†™ä½œå¦‚ä¸‹å½¢å¼ï¼Œçœ‹èµ·æ¥å°±ç†Ÿæ‚‰å¤šäº†ã€‚

![img](https://img-blog.csdnimg.cn/20210521115247963.png#pic_center)

## 6.6 [tensorä¸­ç»´åº¦çš„ç†è§£](https://blog.csdn.net/AlexFaker/article/details/122526169?ops_request_misc=&request_id=&biz_id=102&utm_term=tensor%20%E7%BB%B4%E5%BA%A6&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-122526169.142^v94^insert_down28v1&spm=1018.2226.3001.4187)

```py
import torch

a = torch.randn(3, 4, 5)

print(a)

b = torch.cat((a,a), dim=0)
print(b)

c = torch.cat((a,a), dim=1)
print(c)

d = torch.cat((a,a), dim=2)
print(d)
```

```py
#è¾“å‡º a
tensor([[[ 0.0696,  0.6560,  0.2202, -1.0453,  0.9021],
         [-0.1584, -0.9985, -1.1443, -1.4210, -0.4188],
         [ 1.4070,  2.9814, -2.1767,  1.0888,  0.9540],
         [ 0.3563, -0.7126,  0.2440, -0.1334, -1.0844]],

        [[ 0.2997,  0.8679, -0.8382,  0.8501, -1.4777],
         [-0.2198, -0.0803, -0.4598, -0.0678,  0.1530],
         [-0.4743, -0.5473, -1.2885, -1.7756, -0.4839],
         [ 0.8187, -0.0167,  1.6490,  0.4461, -1.6552]],

        [[ 1.3202, -0.8440,  0.1945,  0.3633,  0.2360],
         [ 1.0943,  2.1030, -0.5662, -0.8079, -1.3058],
         [ 0.6459, -0.2108, -0.8447, -0.7190,  0.3210],
         [-0.1285,  1.5799,  0.1454,  1.6499, -1.3747]]])
# b = torch.cat((a,a), dim=0)  -> è¿™é‡Œçš„0ç»´å¯¹åº”çš„æ˜¯açš„ç¬¬ä¸€ä¸ª3ï¼Œæœ€é«˜ç»´æ‹¼æ¥
tensor([[[ 0.0696,  0.6560,  0.2202, -1.0453,  0.9021],
         [-0.1584, -0.9985, -1.1443, -1.4210, -0.4188],
         [ 1.4070,  2.9814, -2.1767,  1.0888,  0.9540],
         [ 0.3563, -0.7126,  0.2440, -0.1334, -1.0844]],

        [[ 0.2997,  0.8679, -0.8382,  0.8501, -1.4777],
         [-0.2198, -0.0803, -0.4598, -0.0678,  0.1530],
         [-0.4743, -0.5473, -1.2885, -1.7756, -0.4839],
         [ 0.8187, -0.0167,  1.6490,  0.4461, -1.6552]],

        [[ 1.3202, -0.8440,  0.1945,  0.3633,  0.2360],
         [ 1.0943,  2.1030, -0.5662, -0.8079, -1.3058],
         [ 0.6459, -0.2108, -0.8447, -0.7190,  0.3210],
         [-0.1285,  1.5799,  0.1454,  1.6499, -1.3747]],

        [[ 0.0696,  0.6560,  0.2202, -1.0453,  0.9021],
         [-0.1584, -0.9985, -1.1443, -1.4210, -0.4188],
         [ 1.4070,  2.9814, -2.1767,  1.0888,  0.9540],
         [ 0.3563, -0.7126,  0.2440, -0.1334, -1.0844]],

        [[ 0.2997,  0.8679, -0.8382,  0.8501, -1.4777],
         [-0.2198, -0.0803, -0.4598, -0.0678,  0.1530],
         [-0.4743, -0.5473, -1.2885, -1.7756, -0.4839],
         [ 0.8187, -0.0167,  1.6490,  0.4461, -1.6552]],

        [[ 1.3202, -0.8440,  0.1945,  0.3633,  0.2360],
         [ 1.0943,  2.1030, -0.5662, -0.8079, -1.3058],
         [ 0.6459, -0.2108, -0.8447, -0.7190,  0.3210],
         [-0.1285,  1.5799,  0.1454,  1.6499, -1.3747]]])
#c = torch.cat((a,a), dim=1)  -> 1ç»´å¯¹åº”ç¬¬äºŒç»´ï¼Œåˆ—æ‹¼æ¥
tensor([[[ 0.0696,  0.6560,  0.2202, -1.0453,  0.9021],
         [-0.1584, -0.9985, -1.1443, -1.4210, -0.4188],
         [ 1.4070,  2.9814, -2.1767,  1.0888,  0.9540],
         [ 0.3563, -0.7126,  0.2440, -0.1334, -1.0844],
         [ 0.0696,  0.6560,  0.2202, -1.0453,  0.9021],
         [-0.1584, -0.9985, -1.1443, -1.4210, -0.4188],
         [ 1.4070,  2.9814, -2.1767,  1.0888,  0.9540],
         [ 0.3563, -0.7126,  0.2440, -0.1334, -1.0844]],

        [[ 0.2997,  0.8679, -0.8382,  0.8501, -1.4777],
         [-0.2198, -0.0803, -0.4598, -0.0678,  0.1530],
         [-0.4743, -0.5473, -1.2885, -1.7756, -0.4839],
         [ 0.8187, -0.0167,  1.6490,  0.4461, -1.6552],
         [ 0.2997,  0.8679, -0.8382,  0.8501, -1.4777],
         [-0.2198, -0.0803, -0.4598, -0.0678,  0.1530],
         [-0.4743, -0.5473, -1.2885, -1.7756, -0.4839],
         [ 0.8187, -0.0167,  1.6490,  0.4461, -1.6552]],

        [[ 1.3202, -0.8440,  0.1945,  0.3633,  0.2360],
         [ 1.0943,  2.1030, -0.5662, -0.8079, -1.3058],
         [ 0.6459, -0.2108, -0.8447, -0.7190,  0.3210],
         [-0.1285,  1.5799,  0.1454,  1.6499, -1.3747],
         [ 1.3202, -0.8440,  0.1945,  0.3633,  0.2360],
         [ 1.0943,  2.1030, -0.5662, -0.8079, -1.3058],
         [ 0.6459, -0.2108, -0.8447, -0.7190,  0.3210],
         [-0.1285,  1.5799,  0.1454,  1.6499, -1.3747]]])
#d = torch.cat((a,a), dim=2)  -> dim=2å¯¹åº”æœ€ä½ç»´ï¼Œå¯¹åº”è¡Œæ‹¼æ¥
tensor([[[ 0.0696,  0.6560,  0.2202, -1.0453,  0.9021,  0.0696,  0.6560,
           0.2202, -1.0453,  0.9021],
         [-0.1584, -0.9985, -1.1443, -1.4210, -0.4188, -0.1584, -0.9985,
          -1.1443, -1.4210, -0.4188],
         [ 1.4070,  2.9814, -2.1767,  1.0888,  0.9540,  1.4070,  2.9814,
          -2.1767,  1.0888,  0.9540],
         [ 0.3563, -0.7126,  0.2440, -0.1334, -1.0844,  0.3563, -0.7126,
           0.2440, -0.1334, -1.0844]],

        [[ 0.2997,  0.8679, -0.8382,  0.8501, -1.4777,  0.2997,  0.8679,
          -0.8382,  0.8501, -1.4777],
         [-0.2198, -0.0803, -0.4598, -0.0678,  0.1530, -0.2198, -0.0803,
          -0.4598, -0.0678,  0.1530],
         [-0.4743, -0.5473, -1.2885, -1.7756, -0.4839, -0.4743, -0.5473,
          -1.2885, -1.7756, -0.4839],
         [ 0.8187, -0.0167,  1.6490,  0.4461, -1.6552,  0.8187, -0.0167,
           1.6490,  0.4461, -1.6552]],

        [[ 1.3202, -0.8440,  0.1945,  0.3633,  0.2360,  1.3202, -0.8440,
           0.1945,  0.3633,  0.2360],
         [ 1.0943,  2.1030, -0.5662, -0.8079, -1.3058,  1.0943,  2.1030,
          -0.5662, -0.8079, -1.3058],
         [ 0.6459, -0.2108, -0.8447, -0.7190,  0.3210,  0.6459, -0.2108,
          -0.8447, -0.7190,  0.3210],
         [-0.1285,  1.5799,  0.1454,  1.6499, -1.3747, -0.1285,  1.5799,
           0.1454,  1.6499, -1.3747]]])

Process finished with exit code 0

```

## 6.7 å­¦ä¹ é€Ÿç‡Lr

å¤ªå¤§è®­ç»ƒä¸ç¨³å®šï¼Œå¤ªå°æ¨¡å‹è®­ç»ƒå¤ªæ…¢ï¼Œä¸€èˆ¬ä¸€å¼€å§‹è®¾è®¡å¤§ç‚¹çš„é€Ÿç‡è¿›è¡Œå­¦ä¹ ï¼Œå­¦ä¹ åˆ°åé¢å°±é‡‡ç”¨ä¸€ä¸ªæ¯”è¾ƒå°çš„é€Ÿç‡è¿›è¡Œå­¦ä¹ 



## 6.8 [è¿ç§»å­¦ä¹ ](https://blog.csdn.net/sikh_0529/article/details/126864397?ops_request_misc=&request_id=&biz_id=102&utm_term=%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-126864397.142^v94^insert_down28v1&spm=1018.2226.3001.4187)

è¿ç§»å­¦ä¹ (Transfer Learning)æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå°±æ˜¯æŠŠä¸ºä»»åŠ¡ A å¼€å‘çš„æ¨¡å‹ä½œä¸ºåˆå§‹ç‚¹ï¼Œé‡æ–°ä½¿ç”¨åœ¨ä¸ºä»»åŠ¡ B å¼€å‘æ¨¡å‹çš„è¿‡ç¨‹ä¸­ã€‚è¿ç§»å­¦ä¹ æ˜¯é€šè¿‡ä»å·²å­¦ä¹ çš„ç›¸å…³ä»»åŠ¡ä¸­è½¬ç§»çŸ¥è¯†æ¥æ”¹è¿›å­¦ä¹ çš„æ–°ä»»åŠ¡ï¼Œè™½ç„¶å¤§å¤šæ•°æœºå™¨å­¦ä¹ ç®—æ³•éƒ½æ˜¯ä¸ºäº†è§£å†³å•ä¸ªä»»åŠ¡è€Œè®¾è®¡çš„ï¼Œä½†æ˜¯ä¿ƒè¿›è¿ç§»å­¦ä¹ çš„ç®—æ³•çš„å¼€å‘æ˜¯æœºå™¨å­¦ä¹ ç¤¾åŒºæŒç»­å…³æ³¨çš„è¯é¢˜ã€‚ è¿ç§»å­¦ä¹ å¯¹äººç±»æ¥è¯´å¾ˆå¸¸è§ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå‘ç°å­¦ä¹ è¯†åˆ«è‹¹æœå¯èƒ½æœ‰åŠ©äºè¯†åˆ«æ¢¨ï¼Œæˆ–è€…å­¦ä¹ å¼¹å¥ç”µå­ç´å¯èƒ½æœ‰åŠ©äºå­¦ä¹ é’¢ç´ã€‚

æ‰¾åˆ°ç›®æ ‡é—®é¢˜çš„ç›¸ä¼¼æ€§ï¼Œè¿ç§»å­¦ä¹ ä»»åŠ¡å°±æ˜¯ä»ç›¸ä¼¼æ€§å‡ºå‘ï¼Œå°†æ—§é¢†åŸŸ(domain)å­¦ä¹ è¿‡çš„æ¨¡å‹åº”ç”¨åœ¨æ–°é¢†åŸŸä¸Šã€‚




# 7 å®Œæ•´çš„æ¨¡å‹è®­ç»ƒå¥—è·¯
